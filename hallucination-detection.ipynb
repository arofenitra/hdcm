{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 17 14:39:34 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           Off | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   29C    P0              41W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python PyTorch Pipeline for TDA-based Hallucination Detection\n",
    "This pipeline utilizes CodeLlama-7B (a variant of Llama-7B specialized for code\n",
    "), fetches attention maps using PyTorch/HuggingFace, extracts Topological Data Analysis (TDA) features, and classifies the result using LightGBM.\n",
    "1. Setup and Dependencies (Conceptual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import List, Dict, Tuple, Any\n",
    "\n",
    "# --- Conceptual TDA Library Imports ---\n",
    "# NOTE: The actual implementation of these TDA tools (like calculating PH, \n",
    "# Cross-Barcodes, and MTD scores) requires specialized libraries (e.g., ripser, \n",
    "# gudhi, or custom code, which are outside the provided sources).\n",
    "# We use placeholder functions below based on the algorithms described in the sources [3, 4, 7].\n",
    "\n",
    "# Define the LLM Coder: CodeLlama-7B \n",
    "# (Based on Llama-2-7b, noted for its use in code hallucination research [8-10])\n",
    "MODEL_NAME = \"codellama/CodeLlama-7b-hf\" \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set a layer for feature extraction. Research suggests intermediate layers \n",
    "# often achieve near-optimal performance for attention scores [11]. \n",
    "# We target Layer 20, as an example within the commonly optimal range (19 to 23 for 32 layers) [11].\n",
    "TARGET_LAYER = 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. LLM Initialization and Attention Map Extraction (PyTorch)\n",
    "This phase uses PyTorch via the HuggingFace library to load the Llama Coder model and perform a forward pass while recording the internal attention kernel maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from accelerate import infer_auto_device_map, dispatch_model\n",
    "import torch\n",
    "\n",
    "def load_model_and_tokenizer_optimized(model_name: str):\n",
    "    \"\"\"Optimized loading for multi-GPU setup.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Load model with optimized settings\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True,\n",
    "        attn_implementation=\"eager\",  # Force eager attention for output_attentions\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # Enable attention output\n",
    "    model.config.output_attentions = True\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def extract_attention_features(model, tokenizer, prompt: str, code_output: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs a forward pass and extracts attention maps from the target layer.\n",
    "    \n",
    "    The prompt and generated code are concatenated as input [5, 7].\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Prepare input\n",
    "    # In the context of code generation, input sequence x includes the prompt and the generation [5].\n",
    "    full_sequence = prompt + code_output\n",
    "    inputs = tokenizer(full_sequence, return_tensors=\"pt\").to(DEVICE)\n",
    "    \n",
    "    # 2. Run forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_attentions=True)\n",
    "\n",
    "    # Attention maps are extracted from internal layers (white-box setting) [12, 14].\n",
    "    # Attention: Tuple of (Layer x Batch x Head x Seq_Len x Seq_Len) tensors\n",
    "    attentions = outputs.attentions \n",
    "\n",
    "    if TARGET_LAYER >= len(attentions):\n",
    "        raise IndexError(f\"Layer {TARGET_LAYER} out of bounds for model with {len(attentions)} layers.\")\n",
    "\n",
    "    # Select the specific attention map for the target layer (Layer L)\n",
    "    # Shape: (Batch x Head x Seq_Len x Seq_Len)\n",
    "    attn_map_layer_l = attentions[TARGET_LAYER].squeeze(0) \n",
    "\n",
    "    # We return the attention maps (kernel similarity maps) for TDA [15, 16].\n",
    "    return attn_map_layer_l.cpu().numpy(), inputs.input_ids.size(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Topological Data Analysis (TDA) Feature Engineering\n",
    "The TDA approach analyzes the topology of attention maps by treating the attention matrix as a fully-connected weighted graph where nodes are tokens\n",
    ". We extract features based on the concepts of MTD and diagonal sums, which demonstrated relevance for code hallucination detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def conceptual_tda_feature_extraction(attn_map_layer_l: np.ndarray, sequence_length: int, prompt_len: int) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Conceptual function to derive TDA features (MTD, Barcodes, Diagonal Sums).\n",
    "    \n",
    "    We hypothesize shorter persistent barcodes for hallucinated code [User Request].\n",
    "    MTD measures the multiscale topological distance between the generated code manifold \n",
    "    (G) and a reference manifold (P) [5, 18, 19].\n",
    "    \"\"\"\n",
    "    \n",
    "    num_heads = attn_map_layer_l.shape\n",
    "    all_features = {}\n",
    "    \n",
    "    # Identify indices for prompt (P) and generated code (G)\n",
    "    prompt_indices = range(prompt_len)\n",
    "    gen_indices = range(prompt_len, sequence_length)\n",
    "    \n",
    "    for head_idx in range(num_heads):\n",
    "        # The attention matrix A is obtained for the head [5]\n",
    "        A = attn_map_layer_l[head_idx] \n",
    "        \n",
    "        # 1. Attention Graph Construction & Symmetrization [4, 5]\n",
    "        # In TDA, the weighted adjacency graph is often derived using \n",
    "        # wi,j = 1 - max(ai,j, aj,i) for symmetrization [5].\n",
    "        # For this conceptual example, we simulate the input data needed for PH/MTD.\n",
    "        \n",
    "        # 2. Extract Diagonal Attention Features (Diagonal elements sum) [6, 17]\n",
    "        # Diagonal elements (self-attention) are important features [6].\n",
    "        \n",
    "        if prompt_len > 0:\n",
    "            # Sum of diagonal values of attention matrix corresponding to prompt (P) [6]\n",
    "            diag_P_sum = np.sum(A[prompt_indices, prompt_indices]) / prompt_len \n",
    "            all_features[f'diag_P_sum_h{head_idx}'] = diag_P_sum\n",
    "\n",
    "        if len(gen_indices) > 0:\n",
    "            # Sum of diagonal values of attention matrix corresponding to generation (G) [6]\n",
    "            diag_G_sum = np.sum(A[gen_indices, gen_indices]) / len(gen_indices)\n",
    "            all_features[f'diag_G_sum_h{head_idx}'] = diag_G_sum\n",
    "\n",
    "        # 3. Conceptual MTD/Cross-Barcode Features (Topological Features)\n",
    "        # MTD0(P,G), MTD1(P,G), MTD0(G,P), MTD1(G,P) are crucial features [6].\n",
    "        \n",
    "        # MTD0 (0-dimensional homology, related to connected components/persistence length of bars)\n",
    "        # Assuming MTD calculation based on persistent homology (PH) [4]\n",
    "        \n",
    "        # For a hallucinated code (G), the predicted topological stability is often hypothesized \n",
    "        # to be lower or deviate significantly from truthful code (P) [18, 20].\n",
    "\n",
    "        # Placeholder values representing normalized MTD scores [6]:\n",
    "        mtd0_pg = np.random.rand() # MTD0(P, G) / |G|\n",
    "        mtd1_pg = np.random.rand() # MTD1(P, G) / |G|\n",
    "        mtd0_gp = np.random.rand() # MTD0(G, P) / |P|\n",
    "        mtd1_gp = np.random.rand() # MTD1(G, P) / |P|\n",
    "\n",
    "        all_features[f'mtd0_pg_h{head_idx}'] = mtd0_pg\n",
    "        all_features[f'mtd1_pg_h{head_idx}'] = mtd1_pg\n",
    "        all_features[f'mtd0_gp_h{head_idx}'] = mtd0_gp\n",
    "        all_features[f'mtd1_gp_h{head_idx}'] = mtd1_gp\n",
    "\n",
    "    # In a real implementation, normalization (e.g., MinMax normalization) would be applied [21].\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Data Simulation and Feature Aggregation\n",
    "We simulate a dataset structure where features are collected across multiple samples. The target LLM is CodeLlama-7B\n",
    ". Benchmarks like HumanEval or CodeHaluEval provide the necessary (prompt - code) pairs labeled for correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "\n",
    "def load_balanced_code_dataset(num_samples=100):\n",
    "    \"\"\"Load HumanEval dataset and create balanced dataset with hallucinations.\"\"\"\n",
    "    try:\n",
    "        dataset = load_dataset(\"openai_humaneval\", split=\"test\")\n",
    "        \n",
    "        balanced_data = []\n",
    "        \n",
    "        for i, example in enumerate(dataset):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            prompt = example[\"prompt\"]\n",
    "            correct_code = example[\"canonical_solution\"]\n",
    "            \n",
    "            # Add correct example (label 0)\n",
    "            balanced_data.append((prompt, correct_code, 0))\n",
    "            \n",
    "            # Create incorrect/hallucinated version (label 1)\n",
    "            incorrect_code = introduce_hallucination(correct_code)\n",
    "            balanced_data.append((prompt, incorrect_code, 1))\n",
    "            \n",
    "        return balanced_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not load real dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "def introduce_hallucination(code: str) -> str:\n",
    "    \"\"\"Introduce common coding errors to create hallucinated examples.\"\"\"\n",
    "    lines = code.split('\\n')\n",
    "    \n",
    "    if len(lines) <= 1:\n",
    "        return code  # Can't modify single-line functions much\n",
    "    \n",
    "    # Choose a random mutation strategy\n",
    "    strategy = random.choice([\n",
    "        \"off_by_one\", \"wrong_operator\", \"missing_condition\", \n",
    "        \"wrong_variable\", \"infinite_loop\", \"type_error\"\n",
    "    ])\n",
    "    \n",
    "    if strategy == \"off_by_one\":\n",
    "        # Common off-by-one errors\n",
    "        modified_lines = []\n",
    "        for line in lines:\n",
    "            if 'range(' in line and 'len(' in line:\n",
    "                line = line.replace('range(len(', 'range(len(')  # No change, need specific patterns\n",
    "                # More specific off-by-one\n",
    "                if 'range(len(' in line:\n",
    "                    line = line.replace('range(len(', 'range(1, len(')\n",
    "                elif 'range(0, len(' in line:\n",
    "                    line = line.replace('range(0, len(', 'range(0, len(')  # No change\n",
    "                else:\n",
    "                    # Add +1 or -1 randomly\n",
    "                    if random.random() > 0.5:\n",
    "                        line = line.replace('len(', 'len(')  # Placeholder for actual modification\n",
    "            modified_lines.append(line)\n",
    "        return '\\n'.join(modified_lines)\n",
    "    \n",
    "    elif strategy == \"wrong_operator\":\n",
    "        # Replace operators with incorrect ones\n",
    "        replacements = [\n",
    "            ('+', '-'), ('-', '+'), ('*', '/'), ('/', '*'),\n",
    "            ('<', '>'), ('>', '<'), ('<=', '>='), ('>=', '<='),\n",
    "            ('==', '!='), ('!=', '==')\n",
    "        ]\n",
    "        modified_code = code\n",
    "        for old, new in replacements:\n",
    "            if old in modified_code and random.random() > 0.7:\n",
    "                modified_code = modified_code.replace(old, new, 1)\n",
    "                break\n",
    "        return modified_code\n",
    "    \n",
    "    elif strategy == \"missing_condition\":\n",
    "        # Remove or break conditions\n",
    "        if 'if ' in code:\n",
    "            lines = code.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if 'if ' in line and ':' in line:\n",
    "                    # Change condition to always True or False\n",
    "                    if random.random() > 0.5:\n",
    "                        lines[i] = line.replace('if ', 'if True and ')  # Always true\n",
    "                    else:\n",
    "                        lines[i] = line.replace('if ', 'if False or ')  # Always false\n",
    "                    break\n",
    "            return '\\n'.join(lines)\n",
    "        return code\n",
    "    \n",
    "    elif strategy == \"wrong_variable\":\n",
    "        # Use wrong variable names\n",
    "        variables = ['x', 'y', 'z', 'i', 'j', 'k', 'n', 'num', 'val', 'temp']\n",
    "        if variables:\n",
    "            wrong_var = random.choice(variables)\n",
    "            # Find a variable to replace (simple heuristic)\n",
    "            for var in variables:\n",
    "                if var in code and var != wrong_var:\n",
    "                    return code.replace(var, wrong_var)\n",
    "        return code\n",
    "    \n",
    "    elif strategy == \"type_error\":\n",
    "        # Introduce type errors\n",
    "        if 'int(' in code:\n",
    "            return code.replace('int(', 'str(', 1)\n",
    "        elif 'str(' in code:\n",
    "            return code.replace('str(', 'int(', 1)\n",
    "        elif 'float(' in code:\n",
    "            return code.replace('float(', 'str(', 1)\n",
    "        return code\n",
    "    \n",
    "    else:  # infinite_loop\n",
    "        # Change loop conditions to create potential infinite loops\n",
    "        lines = code.split('\\n')\n",
    "        for i, line in enumerate(lines):\n",
    "            if 'while ' in line and ':' in line:\n",
    "                lines[i] = line.replace('while ', 'while True and ')\n",
    "                break\n",
    "            elif 'for ' in line and ' in range(' in line:\n",
    "                lines[i] = line.replace(' in range(', ' in range(1000000)  # Large range')\n",
    "                break\n",
    "        return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. LightGBM Classification\n",
    "We use LightGBM (LGBM) to classify the code as hallucinated or not, based on the extracted TDA features [User Request]. Gradient boosting methods like LGBM and XGBoost were successfully used for this feature set in similar research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_classifier(X: np.ndarray, Y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a classifier for code hallucination detection.\n",
    "    \"\"\"\n",
    "    print(\"--- Training Classifier ---\")\n",
    "    print(f\"Dataset shape: X {X.shape}, Y {Y.shape}\")\n",
    "    print(f\"Class distribution: {np.bincount(Y)}\")\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split, cross_val_score\n",
    "    from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import lightgbm as lgb\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=42, stratify=Y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "    \n",
    "    # Try multiple classifiers\n",
    "    classifiers = {\n",
    "        'LightGBM': lgb.LGBMClassifier(\n",
    "            objective='binary', \n",
    "            metric='binary_logloss', \n",
    "            random_state=42,\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1\n",
    "        ),\n",
    "        'RandomForest': RandomForestClassifier(\n",
    "            n_estimators=100, \n",
    "            random_state=42,\n",
    "            max_depth=10\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    best_score = 0\n",
    "    best_clf = None\n",
    "    best_name = \"\"\n",
    "    \n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"\\n--- Training {name} ---\")\n",
    "        \n",
    "        # Train classifier\n",
    "        clf.fit(X_train, Y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        Y_pred = clf.predict(X_test)\n",
    "        Y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Evaluation\n",
    "        acc = accuracy_score(Y_test, Y_pred)\n",
    "        f1 = f1_score(Y_test, Y_pred)\n",
    "        roc_auc = roc_auc_score(Y_test, Y_proba)\n",
    "        \n",
    "        print(f\"{name} Results:\")\n",
    "        print(f\"  Accuracy: {acc:.4f}\")\n",
    "        print(f\"  F1-Score: {f1:.4f}\")\n",
    "        print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(clf, X, Y, cv=5, scoring='f1')\n",
    "        print(f\"  Cross-val F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        \n",
    "        if roc_auc > best_score:\n",
    "            best_score = roc_auc\n",
    "            best_clf = clf\n",
    "            best_name = name\n",
    "    \n",
    "    print(f\"\\n--- Best Classifier: {best_name} with ROC-AUC {best_score:.4f} ---\")\n",
    "    \n",
    "    # Detailed evaluation for best classifier\n",
    "    Y_pred_best = best_clf.predict(X_test)\n",
    "    Y_proba_best = best_clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(Y_test, Y_pred_best, target_names=['Correct', 'Hallucination']))\n",
    "    \n",
    "    # Feature importance\n",
    "    if hasattr(best_clf, 'feature_importances_'):\n",
    "        print(\"\\nTop 10 Most Important Features:\")\n",
    "        feature_importances = best_clf.feature_importances_\n",
    "        top_indices = np.argsort(feature_importances)[::-1][:10]\n",
    "        \n",
    "        # If you have feature names, use them. Otherwise use indices.\n",
    "        feature_names = [f\"Feature_{i}\" for i in range(len(feature_importances))]\n",
    "        \n",
    "        for i, idx in enumerate(top_indices):\n",
    "            print(f\"  {i+1:2d}. {feature_names[idx]}: {feature_importances[idx]:.4f}\")\n",
    "    \n",
    "    return best_clf, best_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. LLM and Dataset Selection\n",
    "print(f\"Initializing LLM Coder: {MODEL_NAME} (Llama 7B variant) on {DEVICE}\")\n",
    "model, tokenizer = load_model_and_tokenizer_optimized(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def debug_extract_attention_features(model, tokenizer, prompt, code):\n",
    "    \"\"\"Debug version to identify the tuple error.\"\"\"\n",
    "    print(\"DEBUG: Starting extract_attention_features\")\n",
    "    \n",
    "    try:\n",
    "        # Combine prompt and code\n",
    "        full_text = prompt + \"\\n\" + code\n",
    "        print(f\"DEBUG: Full text length: {len(full_text)} chars\")\n",
    "        \n",
    "        # Tokenize\n",
    "        print(\"DEBUG: Tokenizing...\")\n",
    "        inputs = tokenizer(full_text, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        print(f\"DEBUG: Input shapes - input_ids: {inputs['input_ids'].shape}, attention_mask: {inputs['attention_mask'].shape}\")\n",
    "        \n",
    "        # Forward pass\n",
    "        print(\"DEBUG: Running model forward pass...\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_attentions=True)\n",
    "        \n",
    "        print(\"DEBUG: Model forward pass completed\")\n",
    "        \n",
    "        # Get attention maps\n",
    "        attentions = outputs.attentions\n",
    "        print(f\"DEBUG: Type of attentions: {type(attentions)}\")\n",
    "        \n",
    "        if attentions is None:\n",
    "            print(\"DEBUG: No attention maps in output\")\n",
    "            return None, 0\n",
    "        \n",
    "        print(f\"DEBUG: Number of attention layers: {len(attentions)}\")\n",
    "        \n",
    "        # Process attention maps\n",
    "        attn_maps = []\n",
    "        for i, layer_attn in enumerate(attentions):\n",
    "            print(f\"DEBUG: Layer {i} attention shape: {layer_attn.shape}\")\n",
    "            \n",
    "            # Check if layer_attn is a tuple\n",
    "            if isinstance(layer_attn, tuple):\n",
    "                print(f\"DEBUG: Layer {i} attention is tuple with {len(layer_attn)} elements\")\n",
    "                # Take the first element if it's a tuple\n",
    "                layer_attn = layer_attn[0]\n",
    "                print(f\"DEBUG: After taking first element: {layer_attn.shape}\")\n",
    "            \n",
    "            # Average over attention heads\n",
    "            layer_mean = layer_attn.mean(dim=1)  # (batch, seq_len, seq_len)\n",
    "            print(f\"DEBUG: After mean over heads: {layer_mean.shape}\")\n",
    "            \n",
    "            # Remove batch dimension\n",
    "            layer_mean = layer_mean.squeeze(0)  # (seq_len, seq_len)\n",
    "            print(f\"DEBUG: After squeeze: {layer_mean.shape}\")\n",
    "            \n",
    "            attn_maps.append(layer_mean.cpu().numpy())\n",
    "        \n",
    "        seq_len = inputs['input_ids'].shape[1]\n",
    "        print(f\"DEBUG: Final seq_len: {seq_len}\")\n",
    "        print(f\"DEBUG: Number of attention maps: {len(attn_maps)}\")\n",
    "        \n",
    "        return attn_maps, seq_len\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"DEBUG: Error in extract_attention_features: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, 0\n",
    "def extract_attention_features(model, tokenizer, prompt, code):\n",
    "    \"\"\"\n",
    "    Extract attention maps from the model.\n",
    "    Returns: attention_maps (list of numpy arrays), sequence_length (int)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Combine prompt and code\n",
    "        full_text = prompt + \"\\n\" + code\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(full_text, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Get sequence length before forward pass\n",
    "        seq_len = inputs['input_ids'].shape[1]\n",
    "        \n",
    "        # Forward pass with attention output\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_attentions=True)\n",
    "        \n",
    "        # Get attention maps - handle different model output formats\n",
    "        attentions = outputs.attentions\n",
    "        \n",
    "        if attentions is None:\n",
    "            print(\"Warning: No attention maps in model output\")\n",
    "            return None, seq_len\n",
    "        \n",
    "        attn_maps = []\n",
    "        for layer_idx, layer_attention in enumerate(attentions):\n",
    "            # Handle tuple format (some models return tuples)\n",
    "            if isinstance(layer_attention, tuple):\n",
    "                # Usually the first element is the attention tensor\n",
    "                layer_attention = layer_attention[0]\n",
    "            \n",
    "            # layer_attention shape: (batch_size, num_heads, seq_len, seq_len)\n",
    "            if len(layer_attention.shape) == 4:\n",
    "                # Average over attention heads: (batch_size, seq_len, seq_len)\n",
    "                layer_mean = layer_attention.mean(dim=1)\n",
    "                \n",
    "                # Remove batch dimension: (seq_len, seq_len)\n",
    "                if layer_mean.shape[0] == 1:\n",
    "                    layer_mean = layer_mean.squeeze(0)\n",
    "                \n",
    "                attn_maps.append(layer_mean.cpu().numpy())\n",
    "            else:\n",
    "                print(f\"Warning: Unexpected attention shape {layer_attention.shape} at layer {layer_idx}\")\n",
    "                continue\n",
    "        \n",
    "        if len(attn_maps) == 0:\n",
    "            print(\"Warning: No valid attention maps extracted\")\n",
    "            return None, seq_len\n",
    "            \n",
    "        return attn_maps, seq_len\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_attention_features: {e}\")\n",
    "        return None, 0\n",
    "def test_single_sample():\n",
    "    \"\"\"Test the pipeline with a single sample to identify issues.\"\"\"\n",
    "    print(\"=== TESTING SINGLE SAMPLE ===\")\n",
    "    \n",
    "    # Load one sample\n",
    "    balanced_data = load_balanced_code_dataset(num_samples=1)\n",
    "    if not balanced_data:\n",
    "        print(\"Failed to load sample\")\n",
    "        return\n",
    "    \n",
    "    prompt, code, label = balanced_data[0]\n",
    "    print(f\"Prompt: {prompt[:100]}...\")\n",
    "    print(f\"Code: {code[:100]}...\")\n",
    "    print(f\"Label: {label}\")\n",
    "    \n",
    "    # Test attention extraction\n",
    "    print(\"\\n--- Testing Attention Extraction ---\")\n",
    "    attn_maps, seq_len = debug_extract_attention_features(model, tokenizer, prompt, code)\n",
    "    \n",
    "    if attn_maps is None:\n",
    "        print(\"❌ Attention extraction failed\")\n",
    "        return\n",
    "    \n",
    "    print(f\"✅ Attention extraction successful: {len(attn_maps)} layers, seq_len: {seq_len}\")\n",
    "    \n",
    "    # Test TDA feature extraction\n",
    "    print(\"\\n--- Testing TDA Feature Extraction ---\")\n",
    "    try:\n",
    "        prompt_inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        prompt_token_len = prompt_inputs.input_ids.size(1)\n",
    "        \n",
    "        features = conceptual_tda_feature_extraction(attn_maps, seq_len, prompt_token_len)\n",
    "        \n",
    "        if features and len(features) > 0:\n",
    "            print(f\"✅ TDA feature extraction successful: {len(features)} features\")\n",
    "            print(f\"Feature names: {list(features.keys())}\")\n",
    "            print(f\"Feature values: {list(features.values())}\")\n",
    "        else:\n",
    "            print(\"❌ TDA feature extraction returned no features\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ TDA feature extraction failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Run the test\n",
    "test_single_sample()\n",
    "def conceptual_tda_feature_extraction(attn_maps, seq_len, prompt_token_len):\n",
    "    \"\"\"\n",
    "    Extract topological features from attention maps.\n",
    "    Returns: dict of feature names to values\n",
    "    \"\"\"\n",
    "    try:\n",
    "        features = {}\n",
    "        \n",
    "        if attn_maps is None or len(attn_maps) == 0:\n",
    "            return features\n",
    "        \n",
    "        # Basic statistics from attention maps\n",
    "        for layer_idx, attn_map in enumerate(attn_maps):\n",
    "            if attn_map is None:\n",
    "                continue\n",
    "                \n",
    "            # Ensure attn_map is 2D\n",
    "            if len(attn_map.shape) != 2:\n",
    "                print(f\"Warning: Attention map at layer {layer_idx} has shape {attn_map.shape}, expected 2D\")\n",
    "                continue\n",
    "            \n",
    "            # Basic statistics\n",
    "            features[f'layer_{layer_idx}_mean'] = np.mean(attn_map)\n",
    "            features[f'layer_{layer_idx}_std'] = np.std(attn_map)\n",
    "            features[f'layer_{layer_idx}_max'] = np.max(attn_map)\n",
    "            features[f'layer_{layer_idx}_min'] = np.min(attn_map)\n",
    "            \n",
    "            # Prompt-to-code attention ratio (simplified)\n",
    "            if prompt_token_len < seq_len:\n",
    "                prompt_attn = attn_map[:prompt_token_len, :prompt_token_len]\n",
    "                code_attn = attn_map[prompt_token_len:, prompt_token_len:]\n",
    "                \n",
    "                if np.sum(prompt_attn) > 0 and np.sum(code_attn) > 0:\n",
    "                    features[f'layer_{layer_idx}_prompt_code_ratio'] = (\n",
    "                        np.mean(prompt_attn) / np.mean(code_attn)\n",
    "                    )\n",
    "        \n",
    "        # Cross-layer statistics\n",
    "        if len(attn_maps) > 1:\n",
    "            all_means = [np.mean(attn_map) for attn_map in attn_maps if attn_map is not None]\n",
    "            if all_means:\n",
    "                features['cross_layer_mean'] = np.mean(all_means)\n",
    "                features['cross_layer_std'] = np.std(all_means)\n",
    "        \n",
    "        print(f\"Extracted {len(features)} TDA features\")\n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in TDA feature extraction: {e}\")\n",
    "        return {}\n",
    "def run_complete_training_pipeline_fixed(num_samples=5):\n",
    "    \"\"\"Fixed pipeline with better error handling.\"\"\"\n",
    "    print(\"=== CODE HALLUCINATION DETECTION TRAINING PIPELINE (FIXED) ===\")\n",
    "    \n",
    "    # 1. Load balanced dataset\n",
    "    print(\"\\n1. Loading balanced dataset...\")\n",
    "    balanced_data = load_balanced_code_dataset(num_samples)\n",
    "    \n",
    "    if balanced_data is None:\n",
    "        print(\"Failed to load dataset.\")\n",
    "        return None, None, None\n",
    "        \n",
    "    print(f\"Loaded {len(balanced_data)} samples\")\n",
    "    \n",
    "    # 2. Test with one sample first\n",
    "    print(\"\\n2. Testing with single sample...\")\n",
    "    test_single_sample()\n",
    "    \n",
    "    # 3. Extract features from all samples\n",
    "    print(\"\\n3. Extracting features from all samples...\")\n",
    "    feature_list = []\n",
    "    labels = []\n",
    "    successful_samples = 0\n",
    "    \n",
    "    for i, (prompt, code, label) in enumerate(balanced_data):\n",
    "        try:\n",
    "            print(f\"Processing sample {i+1}/{len(balanced_data)} - {'Correct' if label == 0 else 'Hallucination'}\")\n",
    "            \n",
    "            # Get prompt token length\n",
    "            prompt_inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "            prompt_token_len = prompt_inputs.input_ids.size(1)\n",
    "            \n",
    "            # Extract attention features using the fixed version\n",
    "            attn_maps, seq_len = extract_attention_features(model, tokenizer, prompt, code)\n",
    "            \n",
    "            if attn_maps is None:\n",
    "                print(f\"  ⚠️  No attention maps - skipping\")\n",
    "                continue\n",
    "                \n",
    "            if len(attn_maps) == 0:\n",
    "                print(f\"  ⚠️  Empty attention maps - skipping\")\n",
    "                continue\n",
    "                \n",
    "            # Extract TDA features\n",
    "            features = conceptual_tda_feature_extraction(attn_maps, seq_len, prompt_token_len)\n",
    "            \n",
    "            if features and len(features) > 0:\n",
    "                feature_list.append(list(features.values()))\n",
    "                labels.append(label)\n",
    "                successful_samples += 1\n",
    "                print(f\"  ✅ Extracted {len(features)} features\")\n",
    "            else:\n",
    "                print(f\"  ⚠️  No features extracted - skipping\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if successful_samples == 0:\n",
    "        print(\"❌ No successful feature extractions!\")\n",
    "        return None, None, None\n",
    "        \n",
    "    X = np.array(feature_list)\n",
    "    Y = np.array(labels)\n",
    "    \n",
    "    print(f\"\\n✅ Successfully processed {successful_samples}/{len(balanced_data)} samples\")\n",
    "    print(f\"Final dataset: X {X.shape}, Y {Y.shape}\")\n",
    "    \n",
    "    # 4. Train classifier\n",
    "    if len(X) >= 10:  # Need minimum samples for training\n",
    "        print(f\"\\n4. Training classifier...\")\n",
    "        classifier, classifier_name = train_and_evaluate_classifier(X, Y)\n",
    "        return classifier, X, Y\n",
    "    else:\n",
    "        print(f\"❌ Not enough samples for training (need at least 10, got {len(X)})\")\n",
    "        return None, X, Y\n",
    "\n",
    "# Run the fixed pipeline\n",
    "classifier, X, Y = run_complete_training_pipeline_fixed(num_samples=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Minimal test - just check if model works\n",
    "def minimal_test():\n",
    "    \"\"\"Minimal test to check if the model is working.\"\"\"\n",
    "    test_prompt = \"def hello_world():\"\n",
    "    test_code = \"    return 'Hello, World!'\"\n",
    "    \n",
    "    print(\"=== MINIMAL TEST ===\")\n",
    "    \n",
    "    # Test tokenization\n",
    "    try:\n",
    "        inputs = tokenizer(test_prompt + \"\\n\" + test_code, return_tensors=\"pt\")\n",
    "        print(f\"✅ Tokenization works: {inputs['input_ids'].shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Tokenization failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Test model inference\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_attentions=True)\n",
    "        print(f\"✅ Model inference works\")\n",
    "        print(f\"Attentions type: {type(outputs.attentions)}\")\n",
    "        if outputs.attentions:\n",
    "            print(f\"Number of attention layers: {len(outputs.attentions)}\")\n",
    "            print(f\"First layer shape: {outputs.attentions[0].shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Model inference failed: {e}\")\n",
    "        return\n",
    "\n",
    "minimal_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_and_evaluate_lgbm(X[0], X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install human_eval ripser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from accelerate import infer_auto_device_map, dispatch_model\n",
    "import torch\n",
    "import torch\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import List, Dict, Tuple, Any\n",
    "#!/usr/bin/env python\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\n",
    "from human_eval.data import read_problems, write_jsonl\n",
    "from human_eval.execution import check_correctness\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- Conceptual TDA Library Imports ---\n",
    "# NOTE: The actual implementation of these TDA tools (like calculating PH, \n",
    "# Cross-Barcodes, and MTD scores) requires specialized libraries (e.g., ripser, \n",
    "# gudhi, or custom code, which are outside the provided sources).\n",
    "# We use placeholder functions below based on the algorithms described in the sources [3, 4, 7].\n",
    "\n",
    "# Define the LLM Coder: CodeLlama-7B \n",
    "# (Based on Llama-2-7b, noted for its use in code hallucination research [8-10])\n",
    "MODEL_NAME = \"codellama/CodeLlama-7b-hf\" \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set a layer for feature extraction. Research suggests intermediate layers \n",
    "# often achieve near-optimal performance for attention scores [11]. \n",
    "# We target Layer 20, as an example within the commonly optimal range (19 to 23 for 32 layers) [11].\n",
    "TARGET_LAYER = 20 \n",
    "def load_model_and_tokenizer_optimized(model_name: str):\n",
    "    \"\"\"Optimized loading for multi-GPU setup.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Load model with optimized settings\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True,\n",
    "        attn_implementation=\"eager\",  # Force eager attention for output_attentions\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # Enable attention output\n",
    "    model.config.output_attentions = True\n",
    "    \n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def detect_hallucination_improved(generated_code, problem, prompt):\n",
    "    \"\"\"More nuanced hallucination detection\"\"\"\n",
    "    try:\n",
    "        # First check basic syntax and structure\n",
    "        compile(generated_code, '<string>', 'exec')\n",
    "        \n",
    "        # Check for common hallucination patterns\n",
    "        hallucination_indicators = [\n",
    "            ('TODO', 0.8), ('pass', 0.3), ('...', 0.9), \n",
    "            ('raise NotImplementedError', 0.95), ('# Write', 0.6),\n",
    "            ('return None', 0.4), ('return 0', 0.4), ('placeholder', 0.9)\n",
    "        ]\n",
    "        \n",
    "        hallucination_score = 0\n",
    "        for pattern, weight in hallucination_indicators:\n",
    "            if pattern in generated_code:\n",
    "                hallucination_score += weight\n",
    "        \n",
    "        # Execute tests for functional correctness\n",
    "        exec_result = check_correctness(problem, generated_code, timeout=3.0, completion_id=\"temp\")\n",
    "        \n",
    "        # Combined scoring\n",
    "        if not exec_result[\"passed\"]:\n",
    "            if hallucination_score > 0.7:\n",
    "                return True, \"high_confidence_hallucination\"\n",
    "            elif \"exception\" in str(exec_result).lower():\n",
    "                return True, \"execution_error\"\n",
    "            else:\n",
    "                return False, \"minor_functional_error\"  # Not hallucination, just wrong\n",
    "        else:\n",
    "            if hallucination_score > 0.5:\n",
    "                return True, \"suspicious_patterns\"\n",
    "            else:\n",
    "                return False, \"correct\"\n",
    "                \n",
    "    except SyntaxError:\n",
    "        return True, \"syntax_error\"\n",
    "    except Exception as e:\n",
    "        return True, f\"other_error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_problems_by_task(problems, test_ratio=0.3):\n",
    "    \"\"\"Split problems by task_id, not by generations\"\"\"\n",
    "    task_ids = list(problems.keys())\n",
    "    np.random.shuffle(task_ids)\n",
    "    split_idx = int(len(task_ids) * (1 - test_ratio))\n",
    "    \n",
    "    train_problems = {tid: problems[tid] for tid in task_ids[:split_idx]}\n",
    "    test_problems = {tid: problems[tid] for tid in task_ids[split_idx:]}\n",
    "    \n",
    "    return train_problems, test_problems\n",
    "\n",
    "# Usage\n",
    "# train_problems, test_problems = split_problems_by_task(problems)\n",
    "# training_data = collect_training_data(model, tokenizer, train_problems)  # Train on subset\n",
    "# results, pass_at_1 = evaluate_pass_at_k(model, tokenizer, test_problems, classifier, feature_names)  # Test on unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def enhanced_topological_features(dist, prompt_mask, gen_mask):\n",
    "    \"\"\"Enhanced topological feature extraction\"\"\"\n",
    "    n = dist.shape[0]\n",
    "    n_prompt = prompt_mask.sum()\n",
    "    n_gen = gen_mask.sum()\n",
    "    \n",
    "    # Compute persistence with different parameters\n",
    "    dgms = ripser(dist, distance_matrix=True, maxdim=1)['dgms']\n",
    "    \n",
    "    h0_bars = dgms[0][:-1]  # Exclude infinite bar\n",
    "    h1_bars = dgms[1]\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # H0 features\n",
    "    if len(h0_bars) > 0:\n",
    "        h0_persistences = h0_bars[:, 1] - h0_bars[:, 0]\n",
    "        features.update({\n",
    "            'h0_max_persistence': np.max(h0_persistences),\n",
    "            'h0_mean_persistence': np.mean(h0_persistences),\n",
    "            'h0_std_persistence': np.std(h0_persistences),\n",
    "            'h0_num_components': len(h0_bars),\n",
    "            'h0_persistence_entropy': -np.sum(h0_persistences * np.log(h0_persistences + 1e-10))\n",
    "        })\n",
    "    else:\n",
    "        features.update({f'h0_{k}': 0 for k in ['max_persistence', 'mean_persistence', 'std_persistence', 'persistence_entropy']})\n",
    "        features['h0_num_components'] = 0\n",
    "    \n",
    "    # H1 features  \n",
    "    if len(h1_bars) > 0:\n",
    "        h1_persistences = h1_bars[:, 1] - h1_bars[:, 0]\n",
    "        features.update({\n",
    "            'h1_total_persistence': np.sum(h1_persistences),\n",
    "            'h1_max_persistence': np.max(h1_persistences),\n",
    "            'h1_num_loops': len(h1_bars),\n",
    "            'h1_persistence_ratio': np.sum(h1_persistences) / (n_prompt + 1e-10)\n",
    "        })\n",
    "    else:\n",
    "        features.update({f'h1_{k}': 0 for k in ['total_persistence', 'max_persistence', 'persistence_ratio']})\n",
    "        features['h1_num_loops'] = 0\n",
    "    \n",
    "    # Normalized features\n",
    "    features.update({\n",
    "        'mtd_h0_norm': features['h0_max_persistence'] / (n_gen + 1e-10),\n",
    "        'mtd_h1_norm': features['h1_total_persistence'] / (n_prompt + 1e-10),\n",
    "        'component_density': features['h0_num_components'] / (n_gen + 1e-10),\n",
    "        'loop_density': features['h1_num_loops'] / (n_prompt + 1e-10)\n",
    "    })\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def enhanced_attention_analysis(attention, prompt_len):\n",
    "    \"\"\"More sophisticated attention analysis\"\"\"\n",
    "    n = attention.shape[0]\n",
    "    gen_len = n - prompt_len\n",
    "    \n",
    "    # Layer-wise analysis (don't average too early)\n",
    "    features = {}\n",
    "    \n",
    "    # Self-attention patterns\n",
    "    prompt_self = attention[:prompt_len, :prompt_len]\n",
    "    gen_self = attention[prompt_len:, prompt_len:]\n",
    "    \n",
    "    # Cross-attention patterns\n",
    "    gen_to_prompt = attention[prompt_len:, :prompt_len]\n",
    "    prompt_to_gen = attention[:prompt_len, prompt_len:]\n",
    "    \n",
    "    features.update({\n",
    "        # Self-attention metrics\n",
    "        'prompt_self_attn_mean': torch.mean(torch.diag(prompt_self)).item(),\n",
    "        'gen_self_attn_mean': torch.mean(torch.diag(gen_self)).item() if gen_len > 0 else 0,\n",
    "        'prompt_self_attn_std': torch.std(torch.diag(prompt_self)).item(),\n",
    "        \n",
    "        # Cross-attention metrics\n",
    "        'gen_to_prompt_mean': torch.mean(gen_to_prompt).item() if gen_len > 0 else 0,\n",
    "        'gen_to_prompt_max': torch.max(gen_to_prompt).item() if gen_len > 0 else 0,\n",
    "        'attention_imbalance': torch.mean(gen_to_prompt).item() - torch.mean(prompt_to_gen).item() if gen_len > 0 else 0,\n",
    "        \n",
    "        # Entropy measures\n",
    "        'attention_entropy': compute_attention_entropy(attention),\n",
    "        'gen_attention_focus': torch.mean(gen_self).item() / (torch.mean(gen_to_prompt).item() + 1e-10) if gen_len > 0 else 0\n",
    "    })\n",
    "    \n",
    "    return features\n",
    "\n",
    "def compute_attention_entropy(attention_matrix):\n",
    "    \"\"\"Compute entropy of attention distribution\"\"\"\n",
    "    # Flatten and normalize\n",
    "    flat_attn = attention_matrix.flatten()\n",
    "    flat_attn = flat_attn / (torch.sum(flat_attn) + 1e-10)\n",
    "    \n",
    "    # Compute entropy\n",
    "    entropy = -torch.sum(flat_attn * torch.log(flat_attn + 1e-10))\n",
    "    return entropy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_regularized_classifier(data):\n",
    "    \"\"\"Train with proper regularization and validation\"\"\"\n",
    "    # Prepare features\n",
    "    feature_keys = ['mtd_h0_norm', 'mtd_h1_norm', 'prompt_self_attn_mean', \n",
    "                   'gen_self_attn_mean', 'mean_log_prob', 'gen_to_prompt_mean',\n",
    "                   'attention_entropy', 'h1_num_loops', 'component_density']\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for item in data:\n",
    "        features = item[\"features\"]\n",
    "        X.append([features.get(k, 0) for k in feature_keys])\n",
    "        y.append(item[\"label\"])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Check class balance\n",
    "    print(f\"Class distribution: {np.bincount(y)}\")\n",
    "    \n",
    "    # Use proper cross-validation\n",
    "    from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        random_state=42,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,  # Regularization\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(clf, X, y, cv=cv, scoring='f1')\n",
    "    print(f\"Cross-val F1 scores: {cv_scores}\")\n",
    "    print(f\"Mean CV F1: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")\n",
    "    \n",
    "    # Final training\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    return clf, feature_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def realistic_evaluation(model, tokenizer, test_problems, classifier, feature_names):\n",
    "    \"\"\"More realistic evaluation protocol\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for task_id, problem in tqdm(test_problems.items(), desc=\"Realistic Evaluation\"):\n",
    "        prompt = problem[\"prompt\"]\n",
    "        \n",
    "        # Generate multiple candidates (like in real usage)\n",
    "        candidates = []\n",
    "        for seed in SEEDS:\n",
    "            gen_result = generate_with_attention(model, tokenizer, prompt, seed)\n",
    "            features = extract_attention_features(gen_result[\"attention_matrix\"], gen_result[\"prompt_len\"])\n",
    "            \n",
    "            # Add probability features\n",
    "            safe_probs = [max(p, 1e-10) for p in gen_result[\"token_probs\"]]\n",
    "            features['mean_log_prob'] = np.mean(np.log(safe_probs))\n",
    "            \n",
    "            # Predict hallucination probability\n",
    "            feature_vector = [features.get(k, 0) for k in feature_names]\n",
    "            halluc_prob = classifier.predict_proba([feature_vector])[0][1]\n",
    "            \n",
    "            candidates.append({\n",
    "                'code': gen_result[\"generated_text\"],\n",
    "                'halluc_prob': halluc_prob,\n",
    "                'features': features,\n",
    "                'seed': seed\n",
    "            })\n",
    "        \n",
    "        # Strategy 1: Filter out high-hallucination candidates\n",
    "        safe_candidates = [c for c in candidates if c['halluc_prob'] < 0.5]\n",
    "        \n",
    "        if safe_candidates:\n",
    "            # Pick the most confident safe candidate\n",
    "            best_candidate = min(safe_candidates, key=lambda x: x['halluc_prob'])\n",
    "        else:\n",
    "            # If all seem hallucinated, pick the least bad one\n",
    "            best_candidate = min(candidates, key=lambda x: x['halluc_prob'])\n",
    "        \n",
    "        # Evaluate\n",
    "        result = check_correctness(problem, best_candidate['code'], timeout=3.0, completion_id=task_id)\n",
    "        results.append({\n",
    "            \"task_id\": task_id,\n",
    "            \"passed\": result[\"passed\"],\n",
    "            \"hallucination_prob\": best_candidate['halluc_prob'],\n",
    "            \"strategy\": \"safe\" if safe_candidates else \"fallback\"\n",
    "        })\n",
    "    \n",
    "    pass_rate = sum(r[\"passed\"] for r in results) / len(results)\n",
    "    print(f\"Realistic pass rate: {pass_rate:.4f}\")\n",
    "    return results, pass_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM, set_seed\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\n",
    "from human_eval.data import read_problems, write_jsonl\n",
    "from human_eval.execution import check_correctness\n",
    "import lightgbm as lgb\n",
    "\n",
    "# def setup_environment():\n",
    "#     \"\"\"Initialize model, tokenizer, and benchmark problems\"\"\"\n",
    "#     print(f\"Loading model: {MODEL_NAME}\")\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "#     model = AutoModelForCausalLM.from_pretrained(\n",
    "#         MODEL_NAME,\n",
    "#         device_map=\"cuda:0\",\n",
    "#         torch_dtype=torch.float16,\n",
    "\n",
    "#         # load_in_8bit=True,  # Add 8-bit quantization\n",
    "#         output_attentions=True,\n",
    "#         return_dict_in_generate=True\n",
    "#     ).eval()\n",
    "    \n",
    "#     print(f\"Loading benchmark: {BENCHMARK}\")\n",
    "#     if BENCHMARK == \"human_eval\":\n",
    "#         problems = read_problems()\n",
    "#     elif BENCHMARK == \"mbpp\":\n",
    "#         # MBPP loading would go here (simplified for this example)\n",
    "#         raise NotImplementedError(\"MBPP support requires additional setup\")\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unsupported benchmark: {BENCHMARK}\")\n",
    "    \n",
    "#     return model, tokenizer, problems\n",
    "\n",
    "# Configuration - Easy to modify for other models/benchmarks\n",
    "MODEL_NAME = \"codellama/CodeLlama-7b-hf\"  # Can switch to other models\n",
    "BENCHMARK = \"human_eval\"  # Options: \"human_eval\" or \"mbpp\"\n",
    "TEMPERATURE = 0.8\n",
    "TOP_P = 0.95\n",
    "MAX_NEW_TOKENS = 256\n",
    "NUM_SHOTS = 0  # Zero-shot setting (HumanEval standard)\n",
    "NUM_SAMPLES = 5  # Generations per problem for classifier training\n",
    "SEEDS = [0, 1, 2, 3, 4]  # Seeds for reproducibility\n",
    "\n",
    "# Critical: Set up sandbox for code execution\n",
    "os.environ[\"HF_HOME\"] = \"/tmp\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"True\"\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Initialize model, tokenizer, and benchmark problems\"\"\"\n",
    "    print(f\"Loading model: {MODEL_NAME}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # model = AutoModelForCausalLM.from_pretrained(\n",
    "    #     MODEL_NAME,\n",
    "    #     device_map=\"cuda:0\",\n",
    "    #     torch_dtype=torch.float16,\n",
    "\n",
    "    #     # load_in_8bit=True,  # Add 8-bit quantization\n",
    "    #     output_attentions=True,\n",
    "    #     return_dict_in_generate=True\n",
    "    # ).eval()\n",
    "    model_name = MODEL_NAME\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True,\n",
    "        attn_implementation=\"eager\",  # Force eager attention for output_attentions\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # Enable attention output\n",
    "    model.config.output_attentions = True\n",
    "    print(f\"Loading benchmark: {BENCHMARK}\")\n",
    "    if BENCHMARK == \"human_eval\":\n",
    "        problems = read_problems()\n",
    "    elif BENCHMARK == \"mbpp\":\n",
    "        # MBPP loading would go here (simplified for this example)\n",
    "        raise NotImplementedError(\"MBPP support requires additional setup\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported benchmark: {BENCHMARK}\")\n",
    "    \n",
    "    return model, tokenizer, problems\n",
    "def generate_with_attention(model, tokenizer, prompt, seed):\n",
    "    \"\"\"Generate code completion with full attention matrix reconstruction\"\"\"\n",
    "    set_seed(seed)\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=MAX_NEW_TOKENS,\n",
    "            do_sample=True,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_p=TOP_P,\n",
    "            num_return_sequences=1,\n",
    "            output_attentions=True,\n",
    "            output_scores=True,\n",
    "            return_dict_in_generate=True\n",
    "        )\n",
    "    \n",
    "    full_seq = outputs.sequences[0]\n",
    "    generated_ids = full_seq[prompt_len:]\n",
    "    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    total_len = len(full_seq)\n",
    "    \n",
    "    # Initialize full attention matrix (averaged over layers AND heads)\n",
    "    full_attention = torch.zeros((total_len, total_len), device=model.device, dtype=torch.float32)\n",
    "    \n",
    "    # Step 1: Process initial prompt attentions (step 0)\n",
    "    initial_attentions = outputs.attentions[0]  # tuple of (layer0, ..., layer31)\n",
    "    \n",
    "    # Stack all layers, then average over layers AND heads\n",
    "    # Each layer: [1, 32, P, P] → after squeeze: [32, P, P]\n",
    "    stacked_initial = torch.stack([\n",
    "        layer.squeeze(0) for layer in initial_attentions  # remove batch dim\n",
    "    ], dim=0)  # → [num_layers, 32, P, P]\n",
    "    \n",
    "    # Average over layers (dim=0) AND heads (dim=1) → [P, P]\n",
    "    avg_initial = stacked_initial.mean(dim=(0, 1))  # Key fix!\n",
    "    full_attention[:prompt_len, :prompt_len] = avg_initial\n",
    "    \n",
    "    # Step 2: Process generation steps (step 1 onward)\n",
    "    for step, step_attentions in enumerate(outputs.attentions[1:], start=prompt_len):\n",
    "        # step_attentions: tuple of (layer0, ..., layer31), each [1, 32, 1, step+1]\n",
    "        stacked_step = torch.stack([\n",
    "            layer.squeeze(0) for layer in step_attentions  # → [32, 1, step+1]\n",
    "        ], dim=0)  # → [num_layers, 32, 1, step+1]\n",
    "        \n",
    "    # traininingted (G) tokens\n",
    "    n = full_attention.shape[0]\n",
    "    prompt_mask = np.zeros(n, dtype=bool)\n",
    "    prompt_mask[:prompt_len] = True\n",
    "    gen_mask = ~prompt_mask\n",
    "    \n",
    "    return dist, prompt_mask, gen_mask\n",
    "\n",
    "def compute_topological_features(dist, prompt_mask, gen_mask):\n",
    "    \"\"\"Compute MTD-inspired topological features\"\"\"\n",
    "    n_prompt = prompt_mask.sum()\n",
    "    n_gen = gen_mask.sum()\n",
    "    # Compute persistent homology explicitly as distance matrix\n",
    "    dgms = ripser(dist, distance_matrix=True, maxdim=1)['dgms']\n",
    "    # Extract H0 and H1 features\n",
    "    h0_bars = dgms[0][:-1]  # Exclude infinite bar\n",
    "    h1_bars = dgms[1]\n",
    "    # Compute MTD approximation features\n",
    "    features = {\n",
    "        'h0_max_persistence': np.max(h0_bars[:, 1] - h0_bars[:, 0]) if len(h0_bars) > 0 else 0,\n",
    "        'h1_total_persistence': np.sum(h1_bars[:, 1] - h1_bars[:, 0]) if len(h1_bars) > 0 else 0,\n",
    "        'num_h1_bars': len(h1_bars),\n",
    "        'prompt_size': n_prompt,\n",
    "        'gen_size': n_gen\n",
    "    }\n",
    "    # Normalize by component sizes (as specified in requirements)\n",
    "    if n_gen > 0:\n",
    "        features['h0_max_persistence_norm'] = features['h0_max_persistence'] / n_gen\n",
    "    else:\n",
    "        features['h0_max_persistence_norm'] = 0\n",
    "        \n",
    "    if n_prompt > 0:\n",
    "        features['h1_total_persistence_norm'] = features['h1_total_persistence'] / n_prompt\n",
    "    else:\n",
    "        features['h1_total_persistence_norm'] = 0\n",
    "    return features\n",
    "\n",
    "def extract_attention_features(attention, prompt_len):\n",
    "    \"\"\"Extract all required features from attention matrix\"\"\"\n",
    "    dist, prompt_mask, gen_mask = build_distance_matrix(attention, prompt_len)\n",
    "    topo_features = compute_topological_features(dist, prompt_mask, gen_mask)\n",
    "    \n",
    "    # Extract attention statistics\n",
    "    prompt_attn = attention[:prompt_len, :prompt_len]\n",
    "    gen_attn = attention[prompt_len:, prompt_len:]\n",
    "    \n",
    "    features = {\n",
    "        # Topological features (normalized)\n",
    "        'mtd_h0_norm': topo_features['h0_max_persistence_norm'],\n",
    "        'mtd_h1_norm': topo_features['h1_total_persistence_norm'],\n",
    "        \n",
    "        # Attention statistics\n",
    "        'prompt_self_attn': torch.diagonal(prompt_attn).mean().item() if prompt_len > 0 else 0,\n",
    "        'gen_self_attn': torch.diagonal(gen_attn).mean().item() if gen_attn.shape[0] > 0 else 0,\n",
    "        \n",
    "        # Basic features\n",
    "        'prompt_len': prompt_len,\n",
    "        'gen_len': attention.shape[0] - prompt_len,\n",
    "        'h1_num_bars': topo_features['num_h1_bars']\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "def detect_hallucination(generated_code, problem):\n",
    "    \"\"\"Execute code to determine hallucination (failure to pass tests)\"\"\"\n",
    "    try:\n",
    "        # Use the correct signature for HumanEval\n",
    "        result = check_correctness(\n",
    "            problem=problem,          # Pass the entire problem dict\n",
    "            completion=generated_code,\n",
    "            timeout=3.0,\n",
    "            completion_id=\"temp\"\n",
    "        )\n",
    "        return not result[\"passed\"]  # Hallucination = failed tests\n",
    "    except Exception as e:\n",
    "        print(f\"Error in execution for problem: {e}\")\n",
    "        return True  # Treat execution errors as hallucinations\n",
    "\n",
    "def collect_training_data(model, tokenizer, problems):\n",
    "    \"\"\"Generate dataset with features and hallucination labels\"\"\"\n",
    "    training_data = []\n",
    "    for task_id, problem in tqdm(problems.items(), desc=\"Collecting data\"):\n",
    "        prompt = problem[\"prompt\"]\n",
    "        for seed in SEEDS[:NUM_SAMPLES]:\n",
    "            # Generate code with attention\n",
    "            gen_result = generate_with_attention(model, tokenizer, prompt, seed)\n",
    "            # Extract features\n",
    "            attn_features = extract_attention_features(\n",
    "                gen_result[\"attention_matrix\"],\n",
    "                gen_result[\"prompt_len\"]\n",
    "            )\n",
    "            \n",
    "            # Add probability features\n",
    "            # Add probability features with safe log calculation\n",
    "            safe_probs = [max(p, 1e-10) for p in gen_result[\"token_probs\"]]\n",
    "            mean_log_prob = np.mean(np.log(safe_probs))\n",
    "            attn_features.update({\n",
    "                'mean_log_prob': mean_log_prob,\n",
    "                'task_id': task_id,\n",
    "                'seed': seed\n",
    "            })\n",
    "            # Determine hallucination label\n",
    "            is_hallucinated = detect_hallucination(\n",
    "                gen_result[\"generated_text\"],\n",
    "                problem\n",
    "            )\n",
    "            training_data.append({\n",
    "                \"features\": attn_features,\n",
    "                \"label\": int(is_hallucinated),  # 1 = hallucinated, 0 = correct\n",
    "                \"code\": gen_result[\"generated_text\"]\n",
    "            })\n",
    "    \n",
    "    return training_data\n",
    "import pandas as pd \n",
    "def train_classifier(data):\n",
    "    \"\"\"Train XGBoost classifier on collected features\"\"\"\n",
    "    # Prepare data\n",
    "    X = []\n",
    "    y = []\n",
    "    feature_names = None\n",
    "    for item in data :\n",
    "        if feature_names is None:\n",
    "            feature_names = sorted([k for k in item[\"features\"].keys() \n",
    "                                  if k not in [\"task_id\", \"seed\"]])\n",
    "        X.append([item[\"features\"][k] for k in feature_names])\n",
    "        y.append(item[\"label\"])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    # Split data (simple holdout)\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        random_state=42,\n",
    "        verbose=-1  # Silences LightGBM output, remove if you want to see training logs\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Evaluate\n",
    "    train_acc = clf.score(X_train, y_train)\n",
    "    test_acc = clf.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"Classifier trained. Train accuracy: {train_acc:.4f}, Test accuracy: {test_acc:.4f}\")\n",
    "    return clf, feature_names\n",
    "\n",
    "def evaluate_pass_at_k(model, tokenizer, problems, classifier, feature_names):\n",
    "    \"\"\"Evaluate pass@1 with hallucination filtering\"\"\"\n",
    "    results = []\n",
    "    total_correct = 0\n",
    "    # At the start of evaluate_pass_at_k\n",
    "    sample_problem = next(iter(problems.values()))\n",
    "    required_keys = [\"task_id\", \"prompt\", \"test\"]\n",
    "    missing_keys = [k for k in required_keys if k not in sample_problem]\n",
    "    if missing_keys:\n",
    "        raise ValueError(f\"Problem dictionary missing required keys: {missing_keys}\")\n",
    "    for task_id, problem in tqdm(problems.items(), desc=\"Evaluating pass@1\"):\n",
    "        prompt = problem[\"prompt\"]\n",
    "        best_code = None\n",
    "        best_score = -np.inf\n",
    "        # Generate multiple candidates\n",
    "        for seed in SEEDS:\n",
    "            gen_result = generate_with_attention(model, tokenizer, prompt, seed)\n",
    "            attn_features = extract_attention_features(\n",
    "                gen_result[\"attention_matrix\"],\n",
    "                gen_result[\"prompt_len\"]\n",
    "            )\n",
    "            # Add probability features\n",
    "            probs_array = np.array(gen_result[\"token_probs\"])\n",
    "            mean_log_prob = np.mean(np.log(probs_array + 1e-10))  # Add epsilon AFTER converting to array\n",
    "            attn_features['mean_log_prob'] = mean_log_prob\n",
    "            # Prepare features for classifier\n",
    "            # When preparing features for classifier\n",
    "            feature_values = []\n",
    "            for k in feature_names:\n",
    "                if k in attn_features:\n",
    "                    feature_values.append(attn_features[k])\n",
    "                else:\n",
    "                    # Use default value for missing features\n",
    "                    feature_values.append(0.0 if \"norm\" in k or \"prob\" in k else 1.0)\n",
    "            X = pd.DataFrame([feature_values], columns=feature_names)\n",
    "            halluc_prob = classifier.predict_proba(X)[0][1]\n",
    "            \n",
    "            # Score = confidence in non-hallucination + log probability\n",
    "            score = (1 - halluc_prob) + mean_log_prob\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_code = gen_result[\"generated_text\"]\n",
    "        # Execute best candidate\n",
    "        result = check_correctness(\n",
    "            problem=problem,\n",
    "            completion=best_code,\n",
    "            timeout=3.0,\n",
    "            completion_id=task_id\n",
    "        )\n",
    "        is_correct = result[\"passed\"]\n",
    "        total_correct += int(is_correct)\n",
    "        results.append({\n",
    "            \"task_id\": task_id,\n",
    "            \"completion\": best_code,\n",
    "            \"passed\": is_correct,\n",
    "            \"hallucination_prob\": 1 - (best_score - mean_log_prob)  # Approximation\n",
    "        })\n",
    "    \n",
    "    pass_at_1 = total_correct / len(problems)\n",
    "    print(f\"Final pass@1 after hallucination filtering: {pass_at_1:.4f}\")\n",
    "    return results, pass_at_1\n",
    "\n",
    "def generate_with_attention(model, tokenizer, prompt, seed):\n",
    "    \"\"\"Generate code completion with full attention matrix reconstruction\"\"\"\n",
    "    set_seed(seed)\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=MAX_NEW_TOKENS,\n",
    "            do_sample=True,\n",
    "            temperature=TEMPERATURE,\n",
    "            top_p=TOP_P,\n",
    "            num_return_sequences=1,\n",
    "            output_attentions=True,\n",
    "            output_scores=True,\n",
    "            return_dict_in_generate=True\n",
    "        )\n",
    "    \n",
    "    full_seq = outputs.sequences[0]\n",
    "    generated_ids = full_seq[prompt_len:]\n",
    "    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    total_len = len(full_seq)\n",
    "    \n",
    "    # Initialize full attention matrix (averaged over layers AND heads)\n",
    "    full_attention = torch.zeros((total_len, total_len), device=model.device, dtype=torch.float32)\n",
    "    \n",
    "    # Step 1: Process initial prompt attentions (step 0)\n",
    "    initial_attentions = outputs.attentions[0]  # tuple of (layer0, ..., layer31)\n",
    "    \n",
    "    # Stack all layers, then average over layers AND heads\n",
    "    # Each layer: [1, 32, P, P] → after squeeze: [32, P, P]\n",
    "    stacked_initial = torch.stack([\n",
    "        layer.squeeze(0) for layer in initial_attentions  # remove batch dim\n",
    "    ], dim=0)  # → [num_layers, 32, P, P]\n",
    "    \n",
    "    # Average over layers (dim=0) AND heads (dim=1) → [P, P]\n",
    "    avg_initial = stacked_initial.mean(dim=(0, 1))  # Key fix!\n",
    "    full_attention[:prompt_len, :prompt_len] = avg_initial\n",
    "    \n",
    "    # Step 2: Process generation steps (step 1 onward)\n",
    "    for step, step_attentions in enumerate(outputs.attentions[1:], start=prompt_len):\n",
    "        # step_attentions: tuple of (layer0, ..., layer31), each [1, 32, 1, step+1]\n",
    "        stacked_step = torch.stack([\n",
    "            layer.squeeze(0) for layer in step_attentions  # → [32, 1, step+1]\n",
    "        ], dim=0)  # → [num_layers, 32, 1, step+1]\n",
    "    n = len(full_attention)\n",
    "    # traininingted (G) tokens\n",
    "    prompt_mask = np.zeros(n, dtype=bool)\n",
    "    prompt_mask[:prompt_len] = True\n",
    "    gen_mask = ~prompt_mask\n",
    "    \n",
    "    return dist, prompt_mask, gen_mask\n",
    "\n",
    "\n",
    "def analyze_results(results):\n",
    "    \"\"\"Analyze the evaluation results\"\"\"\n",
    "    total = len(results)\n",
    "    passed = sum(r[\"passed\"] for r in results)\n",
    "    avg_halluc_prob = np.mean([r[\"hallucination_prob\"] for r in results])\n",
    "    \n",
    "    strategies = [r.get(\"strategy\", \"unknown\") for r in results]\n",
    "    strategy_counts = {s: strategies.count(s) for s in set(strategies)}\n",
    "    \n",
    "    print(f\"Total test problems: {total}\")\n",
    "    print(f\"Problems passed: {passed} ({passed/total*100:.1f}%)\")\n",
    "    print(f\"Average hallucination probability: {avg_halluc_prob:.4f}\")\n",
    "    print(f\"Strategy usage: {strategy_counts}\")\n",
    "\n",
    "# You'll need to implement the improved functions. Here they are:\n",
    "\n",
    "def split_problems_by_task(problems, test_ratio=0.3):\n",
    "    \"\"\"Split problems by task_id for proper train/test separation\"\"\"\n",
    "    task_ids = list(problems.keys())\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    np.random.shuffle(task_ids)\n",
    "    split_idx = int(len(task_ids) * (1 - test_ratio))\n",
    "    \n",
    "    train_problems = {tid: problems[tid] for tid in task_ids[:split_idx]}\n",
    "    test_problems = {tid: problems[tid] for tid in task_ids[split_idx:]}\n",
    "    \n",
    "    return train_problems, test_problems\n",
    "\n",
    "def collect_training_data_improved(model, tokenizer, problems):\n",
    "    \"\"\"Improved training data collection with better hallucination detection\"\"\"\n",
    "    training_data = []\n",
    "    \n",
    "    for task_id, problem in tqdm(problems.items(), desc=\"Collecting training data\"):\n",
    "        prompt = problem[\"prompt\"]\n",
    "        \n",
    "        for seed in SEEDS[:NUM_SAMPLES]:\n",
    "            try:\n",
    "                # Generate code with attention\n",
    "                gen_result = generate_with_attention(model, tokenizer, prompt, seed)\n",
    "                \n",
    "                # Extract enhanced features\n",
    "                attn_features = extract_attention_features_improved(\n",
    "                    gen_result[\"attention_matrix\"],\n",
    "                    gen_result[\"prompt_len\"]\n",
    "                )\n",
    "                \n",
    "                # Add probability features with safe log calculation\n",
    "                safe_probs = [max(p, 1e-10) for p in gen_result[\"token_probs\"]]\n",
    "                mean_log_prob = np.mean(np.log(safe_probs))\n",
    "                attn_features['mean_log_prob'] = mean_log_prob\n",
    "                \n",
    "                # Determine hallucination label with improved detection\n",
    "                is_hallucinated, reason = detect_hallucination_improved(\n",
    "                    gen_result[\"generated_text\"],\n",
    "                    problem,\n",
    "                    prompt\n",
    "                )\n",
    "                \n",
    "                training_data.append({\n",
    "                    \"features\": attn_features,\n",
    "                    \"label\": int(is_hallucinated),\n",
    "                    \"code\": gen_result[\"generated_text\"],\n",
    "                    \"task_id\": task_id,\n",
    "                    \"seed\": seed,\n",
    "                    \"reason\": reason\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {task_id}, seed {seed}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                # continue\n",
    "                # break\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "def extract_attention_features_improved(attention, prompt_len):\n",
    "    \"\"\"Enhanced feature extraction combining topological and attention features\"\"\"\n",
    "    # Build distance matrix and get topological features\n",
    "    dist, prompt_mask, gen_mask = build_distance_matrix(attention, prompt_len)\n",
    "    topo_features = enhanced_topological_features(dist, prompt_mask, gen_mask)\n",
    "    \n",
    "    # Get enhanced attention features\n",
    "    attn_features = enhanced_attention_analysis(attention, prompt_len)\n",
    "    \n",
    "    # Combine all features\n",
    "    combined_features = {}\n",
    "    combined_features.update(topo_features)\n",
    "    combined_features.update(attn_features)\n",
    "    \n",
    "    # Add basic metadata\n",
    "    combined_features['prompt_len'] = prompt_len\n",
    "    combined_features['gen_len'] = attention.shape[0] - prompt_len\n",
    "    \n",
    "    return combined_features\n",
    "\n",
    "def detect_hallucination_improved(generated_code, problem, prompt):\n",
    "    \"\"\"More nuanced hallucination detection\"\"\"\n",
    "    try:\n",
    "        # First check basic syntax and structure\n",
    "        compile(generated_code, '<string>', 'exec')\n",
    "        \n",
    "        # Check for common hallucination patterns\n",
    "        hallucination_indicators = [\n",
    "            ('TODO', 0.8), ('pass', 0.3), ('...', 0.9), \n",
    "            ('raise NotImplementedError', 0.95), ('# Write', 0.6),\n",
    "            ('return None', 0.4), ('return 0', 0.4), ('placeholder', 0.9)\n",
    "        ]\n",
    "        \n",
    "        hallucination_score = 0\n",
    "        for pattern, weight in hallucination_indicators:\n",
    "            if pattern in generated_code:\n",
    "                hallucination_score += weight\n",
    "        \n",
    "        # Execute tests for functional correctness\n",
    "        exec_result = check_correctness(problem, generated_code, timeout=3.0, completion_id=\"temp\")\n",
    "        \n",
    "        # Combined scoring\n",
    "        if not exec_result[\"passed\"]:\n",
    "            if hallucination_score > 0.7:\n",
    "                return True, \"high_confidence_hallucination\"\n",
    "            elif \"exception\" in str(exec_result).lower():\n",
    "                return True, \"execution_error\"\n",
    "            else:\n",
    "                return False, \"minor_functional_error\"\n",
    "        else:\n",
    "            if hallucination_score > 0.5:\n",
    "                return True, \"suspicious_patterns\"\n",
    "            else:\n",
    "                return False, \"correct\"\n",
    "                \n",
    "    except SyntaxError:\n",
    "        return True, \"syntax_error\"\n",
    "    except Exception as e:\n",
    "        return True, f\"other_error: {e}\"\n",
    "\n",
    "def enhanced_topological_features(dist, prompt_mask, gen_mask):\n",
    "    \"\"\"Enhanced topological feature extraction\"\"\"\n",
    "    n = dist.shape[0]\n",
    "    n_prompt = prompt_mask.sum()\n",
    "    n_gen = gen_mask.sum()\n",
    "    \n",
    "    # Compute persistence with different parameters\n",
    "    dgms = ripser(dist, distance_matrix=True, maxdim=1)['dgms']\n",
    "    \n",
    "    h0_bars = dgms[0][:-1]  # Exclude infinite bar\n",
    "    h1_bars = dgms[1]\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # H0 features\n",
    "    if len(h0_bars) > 0:\n",
    "        h0_persistences = h0_bars[:, 1] - h0_bars[:, 0]\n",
    "        features.update({\n",
    "            'h0_max_persistence': float(np.max(h0_persistences)),\n",
    "            'h0_mean_persistence': float(np.mean(h0_persistences)),\n",
    "            'h0_std_persistence': float(np.std(h0_persistences)),\n",
    "            'h0_num_components': len(h0_bars),\n",
    "        })\n",
    "    else:\n",
    "        features.update({f'h0_{k}': 0 for k in ['max_persistence', 'mean_persistence', 'std_persistence']})\n",
    "        features['h0_num_components'] = 0\n",
    "    \n",
    "    # H1 features  \n",
    "    if len(h1_bars) > 0:\n",
    "        h1_persistences = h1_bars[:, 1] - h1_bars[:, 0]\n",
    "        features.update({\n",
    "            'h1_total_persistence': float(np.sum(h1_persistences)),\n",
    "            'h1_max_persistence': float(np.max(h1_persistences)),\n",
    "            'h1_num_loops': len(h1_bars),\n",
    "        })\n",
    "    else:\n",
    "        features.update({f'h1_{k}': 0 for k in ['total_persistence', 'max_persistence']})\n",
    "        features['h1_num_loops'] = 0\n",
    "    \n",
    "    # Normalized features\n",
    "    features.update({\n",
    "        'mtd_h0_norm': features['h0_max_persistence'] / (n_gen + 1e-10),\n",
    "        'mtd_h1_norm': features['h1_total_persistence'] / (n_prompt + 1e-10),\n",
    "        'component_density': features['h0_num_components'] / (n_gen + 1e-10),\n",
    "        'loop_density': features['h1_num_loops'] / (n_prompt + 1e-10)\n",
    "    })\n",
    "    \n",
    "    return features\n",
    "\n",
    "def enhanced_attention_analysis(attention, prompt_len):\n",
    "    \"\"\"More sophisticated attention analysis\"\"\"\n",
    "    n = attention.shape[0]\n",
    "    gen_len = n - prompt_len\n",
    "    \n",
    "    # Convert to numpy for easier manipulation if it's a tensor\n",
    "    if torch.is_tensor(attention):\n",
    "        attention_np = attention.cpu().numpy()\n",
    "    else:\n",
    "        attention_np = attention\n",
    "    \n",
    "    features = {}\n",
    "    \n",
    "    # Self-attention patterns\n",
    "    prompt_self = attention_np[:prompt_len, :prompt_len]\n",
    "    gen_self = attention_np[prompt_len:, prompt_len:] if gen_len > 0 else np.array([])\n",
    "    \n",
    "    # Cross-attention patterns\n",
    "    gen_to_prompt = attention_np[prompt_len:, :prompt_len] if gen_len > 0 else np.array([])\n",
    "    \n",
    "    features.update({\n",
    "        # Self-attention metrics\n",
    "        'prompt_self_attn_mean': float(np.mean(np.diag(prompt_self))) if prompt_len > 0 else 0,\n",
    "        'gen_self_attn_mean': float(np.mean(np.diag(gen_self))) if gen_self.size > 0 else 0,\n",
    "        'prompt_self_attn_std': float(np.std(np.diag(prompt_self))) if prompt_len > 0 else 0,\n",
    "        \n",
    "        # Cross-attention metrics\n",
    "        'gen_to_prompt_mean': float(np.mean(gen_to_prompt)) if gen_to_prompt.size > 0 else 0,\n",
    "        'gen_to_prompt_max': float(np.max(gen_to_prompt)) if gen_to_prompt.size > 0 else 0,\n",
    "    })\n",
    "    \n",
    "    return features\n",
    "\n",
    "def train_regularized_classifier(data):\n",
    "    \"\"\"Train with proper regularization and validation\"\"\"\n",
    "    # Define the feature keys we want to use\n",
    "    feature_keys = ['mtd_h0_norm', 'mtd_h1_norm', 'prompt_self_attn_mean', \n",
    "                   'gen_self_attn_mean', 'mean_log_prob', 'gen_to_prompt_mean',\n",
    "                   'h1_num_loops', 'component_density', 'prompt_len', 'gen_len']\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for item in data:\n",
    "        features = item[\"features\"]\n",
    "        X.append([features.get(k, 0) for k in feature_keys])\n",
    "        y.append(item[\"label\"])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Check class balance\n",
    "    print(f\"Class distribution: {np.bincount(y)}\")\n",
    "    \n",
    "    # Use proper cross-validation\n",
    "    from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        random_state=42,\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(clf, X, y, cv=cv, scoring='f1')\n",
    "    print(f\"Cross-val F1 scores: {cv_scores}\")\n",
    "    print(f\"Mean CV F1: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")\n",
    "    \n",
    "    # Final training on all data\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    return clf, feature_keys\n",
    "\n",
    "def realistic_evaluation(model, tokenizer, test_problems, classifier, feature_names):\n",
    "    \"\"\"More realistic evaluation protocol\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for task_id, problem in tqdm(test_problems.items(), desc=\"Realistic Evaluation\"):\n",
    "        prompt = problem[\"prompt\"]\n",
    "        \n",
    "        # Generate multiple candidates\n",
    "        candidates = []\n",
    "        for seed in SEEDS:\n",
    "            try:\n",
    "                gen_result = generate_with_attention(model, tokenizer, prompt, seed)\n",
    "                features = extract_attention_features_improved(\n",
    "                    gen_result[\"attention_matrix\"], \n",
    "                    gen_result[\"prompt_len\"]\n",
    "                )\n",
    "                \n",
    "                # Add probability features\n",
    "                safe_probs = [max(p, 1e-10) for p in gen_result[\"token_probs\"]]\n",
    "                features['mean_log_prob'] = np.mean(np.log(safe_probs))\n",
    "                \n",
    "                # Predict hallucination probability\n",
    "                feature_vector = [features.get(k, 0) for k in feature_names]\n",
    "                halluc_prob = classifier.predict_proba([feature_vector])[0][1]\n",
    "                \n",
    "                candidates.append({\n",
    "                    'code': gen_result[\"generated_text\"],\n",
    "                    'halluc_prob': halluc_prob,\n",
    "                    'features': features,\n",
    "                    'seed': seed\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating candidate for {task_id}, seed {seed}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Strategy: Filter out high-hallucination candidates\n",
    "        safe_candidates = [c for c in candidates if c['halluc_prob'] < 0.5]\n",
    "        \n",
    "        if safe_candidates:\n",
    "            # Pick the most confident safe candidate\n",
    "            best_candidate = min(safe_candidates, key=lambda x: x['halluc_prob'])\n",
    "            strategy = \"safe\"\n",
    "        else:\n",
    "            # If all seem hallucinated, pick the least bad one\n",
    "            best_candidate = min(candidates, key=lambda x: x['halluc_prob'])\n",
    "            strategy = \"fallback\"\n",
    "        \n",
    "        # Evaluate\n",
    "        result = check_correctness(problem, best_candidate['code'], timeout=3.0, completion_id=task_id)\n",
    "        results.append({\n",
    "            \"task_id\": task_id,\n",
    "            \"passed\": result[\"passed\"],\n",
    "            \"hallucination_prob\": best_candidate['halluc_prob'],\n",
    "            \"strategy\": strategy\n",
    "        })\n",
    "    \n",
    "    pass_rate = sum(r[\"passed\"] for r in results) / len(results)\n",
    "    print(f\"Realistic pass rate: {pass_rate:.4f}\")\n",
    "    return results, pass_rate\n",
    "\n",
    "# Don't forget to add your existing functions:\n",
    "# - setup_environment()\n",
    "# - generate_with_attention()\n",
    "# - build_distance_matrix() \n",
    "# - etc.\n",
    "\n",
    "\n",
    "# def main():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 0: Setup environment\n",
    "print(\"=== SETTING UP ENVIRONMENT ===\")\n",
    "model, tokenizer, problems = setup_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Split problems for proper evaluation\n",
    "print(\"\\n=== SPLITTING PROBLEMS ===\")\n",
    "train_problems, test_problems = split_problems_by_task(problems, test_ratio=0.3)\n",
    "print(f\"Training problems: {len(train_problems)}, Test problems: {len(test_problems)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Collect training data from TRAINING problems only\n",
    "print(\"\\n=== COLLECTING TRAINING DATA ===\")\n",
    "training_data = collect_training_data_improved(model, tokenizer, train_problems)\n",
    "\n",
    "# Save raw data for analysis\n",
    "with open(\"training_data.json\", \"w\") as f:\n",
    "    json.dump([{**item, \"features\": {k: float(v) if isinstance(v, (np.float32, np.float64)) else v \n",
    "                                    for k,v in item[\"features\"].items()}} \n",
    "                for item in training_data], f, indent=2)\n",
    "print(f\"Saved {len(training_data)} training samples to training_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Train regularized classifier\n",
    "print(\"\\n=== TRAINING HALLUCINATION CLASSIFIER ===\")\n",
    "classifier, feature_names = train_regularized_classifier(training_data)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump({\n",
    "    \"classifier\": classifier,\n",
    "    \"feature_names\": feature_names\n",
    "}, \"hallucination_detector.joblib\")\n",
    "print(\"Saved classifier to hallucination_detector.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Evaluate on UNSEEN test problems\n",
    "print(\"\\n=== EVALUATING ON TEST PROBLEMS ===\")\n",
    "results, pass_at_1 = realistic_evaluation(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    test_problems, \n",
    "    classifier, \n",
    "    feature_names\n",
    ")\n",
    "\n",
    "# Save results\n",
    "write_jsonl(\"samples.jsonl\", results)\n",
    "print(f\"Results saved to samples.jsonl. Final pass@1: {pass_at_1:.4f}\")\n",
    "\n",
    "# Step 5: Additional analysis\n",
    "print(\"\\n=== PERFORMANCE ANALYSIS ===\")\n",
    "analyze_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from transformers) (3.20.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.3/770.3 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.6/782.6 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Installing collected packages: safetensors, regex, pyyaml, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.2.0 huggingface-hub-0.36.0 pyyaml-6.0.3 regex-2025.11.3 safetensors-0.6.2 tokenizers-0.22.1 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==1.8.0\n",
      "  Downloading datasets-1.8.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from datasets==1.8.0) (1.26.4)\n",
      "Collecting pyarrow<4.0.0,>=1.0.0 (from datasets==1.8.0)\n",
      "  Downloading pyarrow-3.0.0.tar.gz (682 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32minstalling build dependencies for pyarrow\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[1258 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version < \"3.9\"' don't match your environment\n",
      "  \u001b[31m   \u001b[0m Collecting cython>=0.29\n",
      "  \u001b[31m   \u001b[0m   Downloading cython-3.2.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting numpy==1.19.4\n",
      "  \u001b[31m   \u001b[0m   Downloading numpy-1.19.4.zip (7.3 MB)\n",
      "  \u001b[31m   \u001b[0m \u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m7.1/7.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[?25h  Installing build dependencies: started\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  \u001b[31m   \u001b[0m Collecting setuptools\n",
      "  \u001b[31m   \u001b[0m   Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting setuptools_scm\n",
      "  \u001b[31m   \u001b[0m   Using cached setuptools_scm-9.2.2-py3-none-any.whl.metadata (7.7 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting wheel\n",
      "  \u001b[31m   \u001b[0m   Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting packaging>=20 (from setuptools_scm)\n",
      "  \u001b[31m   \u001b[0m   Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "  \u001b[31m   \u001b[0m Collecting tomli>=1 (from setuptools_scm)\n",
      "  \u001b[31m   \u001b[0m   Downloading tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "  \u001b[31m   \u001b[0m Downloading cython-3.2.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "  \u001b[31m   \u001b[0m \u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "  \u001b[31m   \u001b[0m Using cached setuptools_scm-9.2.2-py3-none-any.whl (62 kB)\n",
      "  \u001b[31m   \u001b[0m Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "  \u001b[31m   \u001b[0m Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "  \u001b[31m   \u001b[0m Downloading tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "  \u001b[31m   \u001b[0m Building wheels for collected packages: numpy\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): started\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): still running...\n",
      "  \u001b[31m   \u001b[0m   Building wheel for numpy (pyproject.toml): finished with status 'error'\n",
      "  \u001b[31m   \u001b[0m   \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for numpy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m╰─>\u001b[0m \u001b[31m[1208 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m setup.py:67: RuntimeWarning: NumPy 1.19.4 may not yet support Python 3.10.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Running from numpy source directory.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_bounded_integers.pxd.in has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Processing numpy/random/_bounded_integers.pyx\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/mtrand.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_pcg64.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/bit_generator.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_sfc64.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_common.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_bounded_integers.pyx.in has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_philox.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_generator.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/random/_mt19937.pyx has not changed\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Cythonizing sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m blas_opt_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m blas_mkl_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m customize UnixCCompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries mkl_rt not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m blis_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries blis not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m openblas_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries openblas not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_3_10_blas_threads_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Setting PTATLAS=ATLAS\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64/atlas', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_3_10_blas_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64/atlas', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_blas_threads_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Setting PTATLAS=ATLAS\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64/atlas', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_blas_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64/atlas', '/usr/lib64/sse2', '/usr/lib64', '/usr/lib/sse2', '/usr/lib', '/usr/lib/sse2', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m accelerate_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /tmp/pip-install-3fix0_i7/numpy_8e5b1b7ca08b4fe594741a5e5599eb08/numpy/distutils/system_info.py:1914: UserWarning:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Optimized (vendor) Blas libraries are not found.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Falls back to netlib Blas library which has worse performance.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     A better performance should be easily gained by switching\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Blas library.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   if self._calc_info(blas):\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m blas_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries blas not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /tmp/pip-install-3fix0_i7/numpy_8e5b1b7ca08b4fe594741a5e5599eb08/numpy/distutils/system_info.py:1914: UserWarning:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Blas (http://www.netlib.org/blas/) libraries not found.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Directories to search for the libraries can be specified in the\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     numpy/distutils/site.cfg file (section [blas]) or by setting\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     the BLAS environment variable.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   if self._calc_info(blas):\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m blas_src_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /tmp/pip-install-3fix0_i7/numpy_8e5b1b7ca08b4fe594741a5e5599eb08/numpy/distutils/system_info.py:1914: UserWarning:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Blas (http://www.netlib.org/blas/) sources not found.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Directories to search for the sources can be specified in the\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     numpy/distutils/site.cfg file (section [blas_src]) or by setting\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     the BLAS_SRC environment variable.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   if self._calc_info(blas):\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m non-existing path in 'numpy/distutils': 'site.cfg'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m lapack_opt_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m lapack_mkl_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries mkl_rt not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m openblas_lapack_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries openblas not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m openblas_clapack_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries openblas,lapack not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m flame_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries flame not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_3_10_threads_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Setting PTATLAS=ATLAS\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /beegfs/home/arofenitra.rarivonjy/ai/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /beegfs/home/arofenitra.rarivonjy/ai/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/local/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64/atlas\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/lib64/atlas\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/lib64/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries tatlas,tatlas not found in /usr/lib/\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_3_10_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /beegfs/home/arofenitra.rarivonjy/ai/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /beegfs/home/arofenitra.rarivonjy/ai/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/local/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64/atlas\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/lib64/atlas\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/lib64/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries satlas,satlas not found in /usr/lib/\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_threads_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Setting PTATLAS=ATLAS\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /beegfs/home/arofenitra.rarivonjy/ai/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /beegfs/home/arofenitra.rarivonjy/ai/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64/atlas\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/lib64/atlas\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/lib64/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries ptf77blas,ptcblas,atlas not found in /usr/lib/\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m atlas_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /beegfs/home/arofenitra.rarivonjy/ai/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /beegfs/home/arofenitra.rarivonjy/ai/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/local/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/local/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64/atlas\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/lib64/atlas\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/lib64/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/lib64\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/lib/sse2\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack_atlas not found in /usr/lib/\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries f77blas,cblas,atlas not found in /usr/lib/\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m <class 'numpy.distutils.system_info.atlas_info'>\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m lapack_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   libraries lapack not found in ['/beegfs/home/arofenitra.rarivonjy/ai/lib', '/usr/local/lib64', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /tmp/pip-install-3fix0_i7/numpy_8e5b1b7ca08b4fe594741a5e5599eb08/numpy/distutils/system_info.py:1748: UserWarning:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Directories to search for the libraries can be specified in the\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     the LAPACK environment variable.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   return getattr(self, '_calc_info_{}'.format(name))()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m lapack_src_info:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /tmp/pip-install-3fix0_i7/numpy_8e5b1b7ca08b4fe594741a5e5599eb08/numpy/distutils/system_info.py:1748: UserWarning:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     Directories to search for the sources can be specified in the\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     the LAPACK_SRC environment variable.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   return getattr(self, '_calc_info_{}'.format(name))()\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   NOT AVAILABLE\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy_linalg_lapack_lite:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   FOUND:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     language = c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     define_macros = [('HAVE_BLAS_ILP64', None), ('BLAS_SYMBOL_SUFFIX', '64_')]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /tmp/pip-build-env-pnjztp_v/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   warnings.warn(msg)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running config_cc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m unifing config_cc, config, build_clib, build_ext, build commands --compiler options\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running config_fc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build_src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m build_src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building py_modules sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building library \"npymath\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   adding 'build/src.linux-x86_64-3.10/numpy/core/src/npymath' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m None - nothing done with h_files = ['build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_internal.h']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building library \"npysort\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   adding 'build/src.linux-x86_64-3.10/numpy/core/src/common' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m None - nothing done with h_files = ['build/src.linux-x86_64-3.10/numpy/core/src/common/npy_sort.h', 'build/src.linux-x86_64-3.10/numpy/core/src/common/npy_partition.h', 'build/src.linux-x86_64-3.10/numpy/core/src/common/npy_binsearch.h']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building library \"npyrandom\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._multiarray_tests\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._multiarray_umath\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   adding 'build/src.linux-x86_64-3.10/numpy/core/src/umath' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   adding 'build/src.linux-x86_64-3.10/numpy/core/src/npymath' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   adding 'build/src.linux-x86_64-3.10/numpy/core/src/common' to include_dirs.\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy.core - nothing done with h_files = ['build/src.linux-x86_64-3.10/numpy/core/src/umath/funcs.inc', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/simd.inc', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.h', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/matmul.h', 'build/src.linux-x86_64-3.10/numpy/core/src/umath/clip.h', 'build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_internal.h', 'build/src.linux-x86_64-3.10/numpy/core/src/common/templ_common.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/config.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/_numpyconfig.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/__multiarray_api.h', 'build/src.linux-x86_64-3.10/numpy/core/include/numpy/__ufunc_api.h']\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._umath_tests\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._rational_tests\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._struct_ufunc_tests\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.core._operand_flag_tests\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.fft._pocketfft_internal\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.linalg.lapack_lite\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m ### Warning:  Using unoptimized lapack ###\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.linalg._umath_linalg\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m ### Warning:  Using unoptimized lapack ###\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._mt19937\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._philox\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._pcg64\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._sfc64\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._common\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random.bit_generator\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._generator\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random._bounded_integers\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building extension \"numpy.random.mtrand\" sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building data_files sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m build_src: building npy-pkg config files\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ctypeslib.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/_pytesttester.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/version.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matlib.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/conftest.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/_distributor_init.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/_globals.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/dual.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/__init__.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/setup.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying build/src.linux-x86_64-3.10/numpy/__config__.py -> build/lib.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/compat\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/py3k.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/_inspect.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/__init__.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/setup.py -> build/lib.linux-x86_64-3.10/numpy/compat\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/compat/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/tests/test_compat.py -> build/lib.linux-x86_64-3.10/numpy/compat/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/compat/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/compat/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_methods.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/machar.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/setup_common.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_ufunc_config.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/umath_tests.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_exceptions.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/shape_base.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/numerictypes.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/umath.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/cversions.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_dtype.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_dtype_ctypes.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/numeric.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/overrides.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/arrayprint.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/multiarray.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/function_base.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/memmap.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/records.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/__init__.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_asarray.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/setup.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/einsumfunc.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_type_aliases.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/defchararray.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_add_newdocs.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/getlimits.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_string_helpers.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/fromnumeric.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/_internal.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/code_generators/generate_numpy_api.py -> build/lib.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_umath.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_indexerrors.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_errstate.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_machar.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_getlimits.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalar_ctors.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_print.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_cpu_features.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_deprecations.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_conversion_utils.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalarprint.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_unicode.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_multiarray.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_overrides.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_api.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalarmath.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/_locales.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_indexing.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_abc.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_einsum.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_numeric.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_longdouble.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalarbuffer.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_datetime.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_arrayprint.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_dtype.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalarinherit.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_scalar_methods.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_defchararray.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_numerictypes.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_records.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_mem_overlap.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_shape_base.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_item_selection.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_memmap.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_umath_complex.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_nditer.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test__exceptions.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_ufunc.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_function_base.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_protocols.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_umath_accuracy.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_extint128.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/core/tests/test_half.py -> build/lib.linux-x86_64-3.10/numpy/core/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/extension.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/line_endings.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/log.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/msvccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/_shell_utils.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/cpuinfo.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/intelccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/lib2def.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/system_info.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/ccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/pathccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/msvc9compiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/misc_util.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/numpy_distribution.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/from_template.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/unixccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/conv_template.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/setup.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/mingw32ccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/npy_pkg_config.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/core.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/exec_command.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying build/src.linux-x86_64-3.10/numpy/distutils/__config__.py -> build/lib.linux-x86_64-3.10/numpy/distutils\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/develop.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/egg_info.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/install_clib.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/install_headers.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/bdist_rpm.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build_ext.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build_clib.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/install_data.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build_py.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/install.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build_src.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/autodist.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/config.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/build_scripts.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/config_compiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/command/sdist.py -> build/lib.linux-x86_64-3.10/numpy/distutils/command\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/ibm.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/absoft.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/compaq.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/g95.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/gnu.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/pg.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/environment.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/sun.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/nv.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/hpux.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/mips.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/lahey.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/vast.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/none.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/intel.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/pathf95.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/fcompiler/nag.py -> build/lib.linux-x86_64-3.10/numpy/distutils/fcompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_mingw32ccompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_system_info.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_exec_command.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_npy_pkg_config.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_fcompiler_gnu.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_fcompiler_intel.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_fcompiler.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_misc_util.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_fcompiler_nagfor.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_from_template.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/distutils/tests/test_shell_utils.py -> build/lib.linux-x86_64-3.10/numpy/distutils/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/basics.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/dispatch.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/structured_arrays.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/indexing.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/ufuncs.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/internals.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/broadcasting.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/glossary.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/creation.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/misc.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/subclassing.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/byteswapping.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/constants.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/doc/__init__.py -> build/lib.linux-x86_64-3.10/numpy/doc\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/common_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/capi_maps.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/__version__.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/use_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/func2subr.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/__main__.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/auxfuncs.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/f90mod_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/cfuncs.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/cb_rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/diagnose.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/f2py2e.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/rules.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/crackfortran.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/__init__.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/setup.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/f2py_testing.py -> build/lib.linux-x86_64-3.10/numpy/f2py\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_mixed.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_compile_function.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_common.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_parameter.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_assumed_shape.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/util.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_quoted_character.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_kind.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_size.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_crackfortran.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_return_complex.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_block_docstring.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_return_logical.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_return_integer.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_array_from_pyobj.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_return_real.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_callback.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_semicolon_split.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_string.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/f2py/tests/test_return_character.py -> build/lib.linux-x86_64-3.10/numpy/f2py/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/fft\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/helper.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/__init__.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/setup.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/_pocketfft.py -> build/lib.linux-x86_64-3.10/numpy/fft\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/tests/test_pocketfft.py -> build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/tests/test_helper.py -> build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/fft/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/fft/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/recfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/financial.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/mixins.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/format.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/arraypad.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/histograms.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/type_check.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/stride_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/shape_base.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/index_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/twodim_base.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/arraysetops.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/user_array.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/polynomial.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/npyio.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/function_base.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/_iotools.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/nanfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/__init__.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/setup.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/ufunclike.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/scimath.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/_version.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/utils.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/arrayterator.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/_datasource.py -> build/lib.linux-x86_64-3.10/numpy/lib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_format.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_polynomial.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_arraysetops.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_stride_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test__iotools.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_packbits.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_type_check.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test__datasource.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_io.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test__version.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_twodim_base.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_mixins.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_utils.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_shape_base.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_index_tricks.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_recfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_arraypad.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_nanfunctions.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_function_base.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_financial.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_ufunclike.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_arrayterator.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/lib/tests/test_histograms.py -> build/lib.linux-x86_64-3.10/numpy/lib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/linalg.py -> build/lib.linux-x86_64-3.10/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/__init__.py -> build/lib.linux-x86_64-3.10/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/setup.py -> build/lib.linux-x86_64-3.10/numpy/linalg\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/tests/test_linalg.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/tests/test_deprecations.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/tests/test_build.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/linalg/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/linalg/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/mrecords.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/extras.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/__init__.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/bench.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/testutils.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/setup.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/timer_comparison.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/core.py -> build/lib.linux-x86_64-3.10/numpy/ma\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_deprecations.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_mrecords.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_subclassing.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_old_ma.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_extras.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/ma/tests/test_core.py -> build/lib.linux-x86_64-3.10/numpy/ma/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/defmatrix.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/__init__.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/setup.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_interaction.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_matrix_linalg.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_multiarray.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_masked_matrix.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_numeric.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/test_defmatrix.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/matrixlib/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/matrixlib/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/_polybase.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/hermite_e.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/polyutils.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/chebyshev.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/polynomial.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/legendre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/laguerre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/__init__.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/setup.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/hermite.py -> build/lib.linux-x86_64-3.10/numpy/polynomial\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_polynomial.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_laguerre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_polyutils.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_hermite_e.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_printing.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_chebyshev.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_hermite.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_legendre.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/polynomial/tests/test_classes.py -> build/lib.linux-x86_64-3.10/numpy/polynomial/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/random\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/_pickle.py -> build/lib.linux-x86_64-3.10/numpy/random\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/__init__.py -> build/lib.linux-x86_64-3.10/numpy/random\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/setup.py -> build/lib.linux-x86_64-3.10/numpy/random\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_random.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_direct.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_regression.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_randomstate_regression.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_generator_mt19937.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_smoke.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_randomstate.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_seed_sequence.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_extending.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/random/tests/test_generator_mt19937_regressions.py -> build/lib.linux-x86_64-3.10/numpy/random/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/testing\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/print_coercion_tables.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/__init__.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/setup.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/utils.py -> build/lib.linux-x86_64-3.10/numpy/testing\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/parameterized.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/decorators.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/noseclasses.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/nosetester.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/__init__.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/_private/utils.py -> build/lib.linux-x86_64-3.10/numpy/testing/_private\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/tests/test_utils.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/tests/test_doctesting.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/testing/tests/test_decorators.py -> build/lib.linux-x86_64-3.10/numpy/testing/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_warnings.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_ctypeslib.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_public_api.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_reloading.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_numpy_version.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_matlib.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/__init__.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m copying numpy/tests/test_scripts.py -> build/lib.linux-x86_64-3.10/numpy/tests\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build_clib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m customize UnixCCompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m customize UnixCCompiler using new_build_clib\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building 'npymath' library\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compiling C sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m C compiler: /trinity/shared/opt/rh/gcc-12.2.0/bin/gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/numpy/core/src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/numpy/core/src/npymath\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/build\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/npymath\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compile options: '-Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/beegfs/home/arofenitra.rarivonjy/ai/include -I/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m extra options: '-std=c99'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/npymath/npy_math.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/ieee754.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_complex.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/npymath/halffloat.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m ar: adding 4 object files to build/temp.linux-x86_64-3.10/libnpymath.a\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building 'npysort' library\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compiling C sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m C compiler: /trinity/shared/opt/rh/gcc-12.2.0/bin/gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/npysort\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compile options: '-Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/beegfs/home/arofenitra.rarivonjy/ai/include -I/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m extra options: '-std=c99'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/quicksort.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/mergesort.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/heapsort.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/selection.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/timsort.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/radixsort.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npysort/binsearch.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m ar: adding 7 object files to build/temp.linux-x86_64-3.10/libnpysort.a\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building 'npyrandom' library\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compiling C sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m C compiler: /trinity/shared/opt/rh/gcc-12.2.0/bin/gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/numpy/random\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/numpy/random/src\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/numpy/random/src/distributions\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compile options: '-Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/beegfs/home/arofenitra.rarivonjy/ai/include -I/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m extra options: '-std=c99'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/random/src/distributions/logfactorial.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/random/src/distributions/distributions.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/random/src/distributions/random_mvhg_marginals.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/random/src/distributions/random_hypergeometric.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/random/src/distributions/random_mvhg_count.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m ar: adding 5 object files to build/temp.linux-x86_64-3.10/libnpyrandom.a\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m customize UnixCCompiler\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m customize UnixCCompiler using new_build_ext\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building 'numpy.core._multiarray_tests' extension\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compiling C sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m C compiler: /trinity/shared/opt/rh/gcc-12.2.0/bin/gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/numpy/core/src/common\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/beegfs/home/arofenitra.rarivonjy/ai/include -I/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m extra options: '-std=c99'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/_multiarray_tests.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/common/mem_overlap.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/shared/opt/rh/gcc-12.2.0/bin/gcc -pthread -shared -L/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/lib -Wl,-rpath,/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/lib -L/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/lib -Wl,-rpath,/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/lib build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/_multiarray_tests.o build/temp.linux-x86_64-3.10/numpy/core/src/common/mem_overlap.o -L/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/lib -Lbuild/temp.linux-x86_64-3.10 -lnpymath -o build/lib.linux-x86_64-3.10/numpy/core/_multiarray_tests.cpython-310-x86_64-linux-gnu.so\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m building 'numpy.core._multiarray_umath' extension\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compiling C sources\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m C compiler: /trinity/shared/opt/rh/gcc-12.2.0/bin/gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/numpy/core/src/multiarray\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/numpy/core/src/umath\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/umath\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/common\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/beegfs/home/arofenitra.rarivonjy/ai/include -I/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m extra options: '-std=c99'\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/alloc.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/array_assign_scalar.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/buffer.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/conversion_utils.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/datetime_strings.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/common.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/descriptor.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/einsum.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In function ‘PyDataMem_FREE’,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     inlined from ‘PyDataMem_FREE’ at numpy/core/src/multiarray/alloc.c:291:1,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     inlined from ‘_npy_free_cache’ at numpy/core/src/multiarray/alloc.c:133:5,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     inlined from ‘npy_free_cache’ at numpy/core/src/multiarray/alloc.c:168:5:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/alloc.c:299:14: warning: pointer ‘p’ may be used after ‘free’ [-Wuse-after-free]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   299 |             (*_PyDataMem_eventhook)(ptr, NULL, 0,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   300 |                                     _PyDataMem_eventhook_user_data);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In function ‘PyDataMem_FREE’,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     inlined from ‘_npy_free_cache’ at numpy/core/src/multiarray/alloc.c:133:5,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     inlined from ‘npy_free_cache’ at numpy/core/src/multiarray/alloc.c:168:5:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/alloc.c:294:5: note: call to ‘free’ here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   294 |     free(ptr);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |     ^~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In function ‘PyDataMem_FREE’,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     inlined from ‘PyDataMem_FREE’ at numpy/core/src/multiarray/alloc.c:291:1:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/alloc.c:299:14: warning: pointer ‘ptr’ may be used after ‘free’ [-Wuse-after-free]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   299 |             (*_PyDataMem_eventhook)(ptr, NULL, 0,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   300 |                                     _PyDataMem_eventhook_user_data);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/alloc.c: In function ‘PyDataMem_FREE’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/alloc.c:294:5: note: call to ‘free’ here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   294 |     free(ptr);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |     ^~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/alloc.c: In function ‘PyDataMem_RENEW’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/alloc.c:317:9: warning: pointer ‘ptr’ may be used after ‘realloc’ [-Wuse-after-free]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   317 |         PyTraceMalloc_Untrack(NPY_TRACE_DOMAIN, (npy_uintp)ptr);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/alloc.c:315:14: note: call to ‘realloc’ here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   315 |     result = realloc(ptr, size);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |              ^~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/alloc.c:324:14: warning: pointer ‘ptr’ may be used after ‘realloc’ [-Wuse-after-free]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   324 |             (*_PyDataMem_eventhook)(ptr, result, size,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   325 |                                     _PyDataMem_eventhook_user_data);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/alloc.c:315:14: note: call to ‘realloc’ here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   315 |     result = realloc(ptr, size);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |              ^~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/arrayobject.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/array_assign_array.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/convert.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/datetime_busday.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/calculation.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/ctors.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/arrayfunction_override.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/convert_datatype.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/hashdescr.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/datetime_busdaycal.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/dragon4.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/compiled_base.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/item_selection.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/arraytypes.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/lowlevel_strided_loops.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/multiarraymodule.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/ctors.c: In function ‘array_from_text.constprop’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/ctors.c:3660:8: warning: ‘stop_reading_flag’ may be used uninitialized [-Wmaybe-uninitialized]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  3660 |     if (stop_reading_flag == -2) {\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |        ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/ctors.c:3584:9: note: ‘stop_reading_flag’ was declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  3584 |     int stop_reading_flag;  /* -1 indicates end reached; -2 a parsing error */\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ^~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/datetime.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/dtype_transfer.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/nditer_constr.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c: In function ‘npyiter_replace_axisdata’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:1992:33: warning: writing 8 bytes into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  1992 |     NIT_RESETDATAPTR(iter)[iop] = op_dataptr;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In file included from numpy/core/src/multiarray/nditer_constr.c:16:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [32, 4112] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:1993:32: warning: writing 8 bytes into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  1993 |     NIT_BASEOFFSETS(iter)[iop] = baseoffset;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [40, 6160] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c: In function ‘npyiter_reverse_axis_ordering’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [17, 241] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 1 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [18, 242] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 2 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [19, 243] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 3 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [20, 244] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 4 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [21, 245] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 5 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [22, 246] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 6 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [23, 247] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 7 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [24, 248] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 8 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [25, 249] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 9 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [26, 250] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 10 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [27, 251] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 11 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [28, 252] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 12 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [29, 253] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 13 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:2235:15: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2235 |         *perm = (npy_int8)i;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [30, 254] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 14 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/iterators.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/refcount.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/scalarapi.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c: In function ‘NpyIter_AdvancedNew’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:283:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   283 |         perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 1 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:283:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   283 |         perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [2, 2147483646] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:283:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   283 |         perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [3, 2147483646] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:283:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   283 |         perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [4, 2147483646] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:283:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   283 |         perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [5, 2147483646] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:283:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   283 |         perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [6, 2147483646] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In function ‘npyiter_replace_axisdata’,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     inlined from ‘npyiter_allocate_arrays’ at numpy/core/src/multiarray/nditer_constr.c:2873:13,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m     inlined from ‘NpyIter_AdvancedNew’ at numpy/core/src/multiarray/nditer_constr.c:403:10:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_constr.c:1993:32: warning: writing 8 bytes into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  1993 |     NIT_BASEOFFSETS(iter)[iop] = baseoffset;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h: In function ‘NpyIter_AdvancedNew’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [40, 6152] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/sequence.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/nditer_pywrap.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/shape.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/temp_elide.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src: In function ‘float_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2967:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In file included from /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/Python.h:77,\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m                  from numpy/core/src/multiarray/scalartypes.c.src:3:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2967:12: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |            ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src: In function ‘cfloat_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2975:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2975 |     hashreal = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               ^~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               |\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               double\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2976 |             PyArrayScalar_VAL(obj, C@name@).real);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2975:16: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2975 |     hashreal = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2981:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2981 |     hashimag = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               ^~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               |\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               double\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2982 |             PyArrayScalar_VAL(obj, C@name@).imag);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2981:16: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2981 |     hashimag = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src: In function ‘longdouble_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2967:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2967:12: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |            ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src: In function ‘clongdouble_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2975:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2975 |     hashreal = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               ^~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               |\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               double\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2976 |             PyArrayScalar_VAL(obj, C@name@).real);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2975:16: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2975 |     hashreal = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2981:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2981 |     hashimag = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               ^~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               |\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                               double\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2982 |             PyArrayScalar_VAL(obj, C@name@).imag);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2981:16: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2981 |     hashimag = _Py_HashDouble((double)\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src: In function ‘half_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2997:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2997 |     return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                           |\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                           double\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                                      ^~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2997:12: error: too few arguments to function ‘_Py_HashDouble’\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2997 |     return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |            ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m /trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10/pyhash.h:10:23: note: declared here\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m    10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |                       ^~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src: In function ‘longdouble_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2968:1: warning: control reaches end of non-void function [-Wreturn-type]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2968 | }\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       | ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src: In function ‘float_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2968:1: warning: control reaches end of non-void function [-Wreturn-type]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2968 | }\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       | ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src: In function ‘half_arrtype_hash’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/scalartypes.c.src:2998:1: warning: control reaches end of non-void function [-Wreturn-type]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  2998 | }\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       | ^\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/vdot.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/typeinfo.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/umath/umathmodule.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/usertypes.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/umath/reduction.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/multiarray/nditer_templ.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/number.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/umath/ufunc_object.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/umath/ufunc_type_resolution.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/ieee754.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/umath/override.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/nditer_api.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/npymath/npy_math_complex.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/npymath/npy_math.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/flagsobject.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c: In function ‘npyiter_coalesce_axes’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:1684:24: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  1684 |             perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m In file included from numpy/core/src/multiarray/nditer_api.c:16:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 1 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:1684:24: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  1684 |             perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [2, 253] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:1684:24: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  1684 |             perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [3, 253] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:1684:24: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  1684 |             perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [4, 253] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:1684:24: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  1684 |             perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [5, 253] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:1684:24: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m  1684 |             perm[idim] = (npy_int8)idim;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |             ~~~~~~~~~~~^~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset [6, 253] into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/common/array_assign.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c: In function ‘NpyIter_RemoveAxis’:\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:123:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   123 |         perm[idim] = p;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 1 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:123:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   123 |         perm[idim] = p;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 1 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:123:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   123 |         perm[idim] = p;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 1 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:123:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   123 |         perm[idim] = p;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 1 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:123:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   123 |         perm[idim] = p;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 1 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_api.c:123:20: warning: writing 1 byte into a region of size 0 [-Wstringop-overflow=]\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   123 |         perm[idim] = p;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |         ~~~~~~~~~~~^~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m numpy/core/src/multiarray/nditer_impl.h:148:10: note: at offset 1 into destination object ‘iter_flexdata’ of size 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   148 |     char iter_flexdata;\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/getset.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/npymath/halffloat.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/common/ucsnarrow.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/common/mem_overlap.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/common/npy_cpu_features.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/umath/extobj.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/common/ufunc_override.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/scalarmath.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/common/numpyos.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/common/npy_longdouble.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/mapping.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: numpy/core/src/multiarray/methods.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/matmul.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/clip.c\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m error: Command \"/trinity/shared/opt/rh/gcc-12.2.0/bin/gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/beegfs/home/arofenitra.rarivonjy/ai/include -I/trinity/home/arofenitra.rarivonjy/.pyenv/versions/3.10.12/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.c -o build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.o -MMD -MF build/temp.linux-x86_64-3.10/build/src.linux-x86_64-3.10/numpy/core/src/multiarray/scalartypes.o.d -std=c99\" failed with exit status 1\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m  ERROR: Failed building wheel for numpy\u001b[0m\u001b[31m\n",
      "  \u001b[31m   \u001b[0m \u001b[0mFailed to build numpy\n",
      "  \u001b[31m   \u001b[0m \u001b[1;31merror\u001b[0m: \u001b[1mfailed-wheel-build-for-install\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m×\u001b[0m Failed to build installable wheels for some pyproject.toml based projects\n",
      "  \u001b[31m   \u001b[0m \u001b[31m╰─>\u001b[0m numpy\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31mERROR: Failed to build 'pyarrow' when installing build dependencies for pyarrow\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install datasets==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: git: command not found\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/datasets/Muennighoff/mbpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (4.67.1)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.10.0)\n",
      "Requirement already satisfied: requests in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: networkx in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm accelerate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T09:13:21.721296Z",
     "iopub.status.busy": "2025-11-17T09:13:21.720723Z",
     "iopub.status.idle": "2025-11-17T09:13:21.756851Z",
     "shell.execute_reply": "2025-11-17T09:13:21.756035Z",
     "shell.execute_reply.started": "2025-11-17T09:13:21.721276Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MBPP Hallucination Detection for Code LLMs\n",
    "Compares CodeLlama-7B generated code against MBPP reference solutions\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from datasets import load_dataset\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "# ==================== Configuration ====================\n",
    "class Config:\n",
    "    MODEL_NAME = \"codellama/CodeLlama-7b-hf\"\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    MAX_NEW_TOKENS = 512\n",
    "    TEMPERATURE = 0.2\n",
    "    TOP_P = 0.95\n",
    "    BATCH_SIZE = 1  # For memory efficiency\n",
    "    NUM_SAMPLES = 5  # Number of MBPP samples to evaluate\n",
    "    \n",
    "\n",
    "# ==================== Model Setup ====================\n",
    "class CodeLlamaInference:\n",
    "    def __init__(self, model_name: str, device: str):\n",
    "        print(f\"Loading model: {model_name}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\",\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        self.device = device\n",
    "        print(f\"Model loaded on {device}\")\n",
    "    \n",
    "    # def generate_code(self, prompt: str, max_new_tokens: int = 512, \n",
    "    #                   temperature: float = 0.2, top_p: float = 0.95) -> str:\n",
    "    #     \"\"\"Generate code completion for given prompt\"\"\"\n",
    "    #     inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "    #     with torch.no_grad():\n",
    "    #         outputs = self.model.generate(\n",
    "    #             **inputs,\n",
    "    #             max_new_tokens=max_new_tokens,\n",
    "    #             temperature=temperature,\n",
    "    #             top_p=top_p,\n",
    "    #             do_sample=True,\n",
    "    #             pad_token_id=self.tokenizer.eos_token_id\n",
    "    #         )\n",
    "        \n",
    "    #     generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    #     # Extract only the generated part (remove prompt)\n",
    "    #     generated_code = generated_text[len(prompt):].strip()\n",
    "    #     return generated_code\n",
    "    def generate_code(self, prompt: str, max_new_tokens: int = 512, \n",
    "                      temperature: float = 0.2, top_p: float = 0.95) -> str:\n",
    "        \"\"\"Generate code completion for given prompt with better stopping\"\"\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        # Add stop tokens to prevent excessive generation\n",
    "        stop_tokens = [\"\\n\\n\", \"\\n#\", \"\\ndef \", \"\\nclass \"]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                eos_token_id=self.tokenizer.eos_token_id,\n",
    "                # Add repetition penalty to reduce redundant generation\n",
    "                repetition_penalty=1.1,\n",
    "            )\n",
    "        \n",
    "        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        generated_code = generated_text[len(prompt):].strip()\n",
    "        \n",
    "        # Truncate at reasonable endpoints\n",
    "        for stop_token in stop_tokens:\n",
    "            if stop_token in generated_code:\n",
    "                generated_code = generated_code.split(stop_token)[0]\n",
    "        \n",
    "        return generated_code\n",
    "\n",
    "# ==================== MBPP Dataset Loader ====================\n",
    "# class MBPPDataset:\n",
    "#     def __init__(self, num_samples: int = 10):\n",
    "#         print(\"Loading MBPP dataset...\")\n",
    "#         self.dataset = load_dataset(\"mbpp\", \"sanitized\", split=\"test\")\n",
    "#         self.num_samples = min(num_samples, len(self.dataset))\n",
    "#         print(f\"Loaded {len(self.dataset)} samples, using {self.num_samples}\")\n",
    "    \n",
    "#     def get_prompt(self, example: Dict) -> str:\n",
    "#         \"\"\"Format MBPP example into a prompt for code generation\"\"\"\n",
    "#         # MBPP uses 'prompt' not 'text'\n",
    "#         task_description = example.get('prompt', example.get('text', ''))\n",
    "        \n",
    "#         # Extract function name from reference code\n",
    "#         func_name = 'solution'\n",
    "#         if 'def ' in example['code']:\n",
    "#             try:\n",
    "#                 func_name = example['code'].split('def ')[1].split('(')[0].strip()\n",
    "#             except:\n",
    "#                 pass\n",
    "        \n",
    "#         prompt = f\"\"\"# Task: {task_description}\n",
    "# # Write a Python function to solve this task\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Define the expected structure for a dataset sample\n",
    "DatasetSample = Dict[str, Any]\n",
    "\n",
    "class MBPPDataset:\n",
    "    def __init__(self, num_samples: int = 5, data_path: str = \"mbpp/data/sanitized-mbpp.json\"):\n",
    "        \"\"\"\n",
    "        Initializes the dataset by loading data from a local JSON file.\n",
    "        \n",
    "        Args:\n",
    "            num_samples (int): The maximum number of samples to use.\n",
    "            data_path (str): The path to the local MBPP JSON file.\n",
    "        \"\"\"\n",
    "        print(\"Loading MBPP dataset...\")\n",
    "        \n",
    "        # Replace load_dataset(\"mbpp\", \"sanitized\", split=\"test\") with local file loading\n",
    "        self.dataset: List[DatasetSample] = self._load_local_json(data_path)\n",
    "        \n",
    "        # Check if loading was successful\n",
    "        if not self.dataset:\n",
    "             raise ValueError(f\"Failed to load dataset from path: {data_path}. Please check the path and file content.\")\n",
    "\n",
    "        self.num_samples = min(num_samples, len(self.dataset))\n",
    "        print(f\"Loaded {len(self.dataset)} total samples, using {self.num_samples}\")\n",
    "\n",
    "    def _load_local_json(self, path: str) -> List[DatasetSample]:\n",
    "        \"\"\"Utility function to load a list of dictionaries from a JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                # The 'sanitized-mbpp.json' structure is a single JSON array of objects\n",
    "                data = json.load(f)\n",
    "                return data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file was not found at {path}. Have you run 'git clone' and checked the directory structure?\")\n",
    "            return []\n",
    "        except json.JSONDecodeError:\n",
    "            # Handle potential issue with 'mbpp.json' which is a newline-delimited JSON (JSONL)\n",
    "            # If you were loading 'mbpp.json', you'd need to change the loading logic to read line by line.\n",
    "            print(f\"Error: Could not decode JSON from {path}. Ensure it is a valid JSON array.\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during file loading: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_prompt(self, example: DatasetSample) -> str:\n",
    "        \"\"\"Format MBPP example into a prompt for code generation\"\"\"\n",
    "        # MBPP uses 'prompt' not 'text' in the sanitized dataset\n",
    "        task_description = example.get('prompt', example.get('text', ''))\n",
    "        \n",
    "        # Extract function name from reference code\n",
    "        func_name = 'solution'\n",
    "        if 'def ' in example['code']:\n",
    "            try:\n",
    "                # Basic parsing to find the function name\n",
    "                func_name = example['code'].split('def ')[1].split('(')[0].strip()\n",
    "            except IndexError:\n",
    "                # Fallback if split fails unexpectedly\n",
    "                pass\n",
    "        \n",
    "        prompt = f\"\"\"# Task: {task_description}\n",
    "# Write a Python function to solve this task\n",
    "def {func_name}(\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def get_reference_code(self, example: Dict) -> str:\n",
    "        \"\"\"Get the reference solution from MBPP\"\"\"\n",
    "        return example['code']\n",
    "    \n",
    "    def get_test_cases(self, example: Dict) -> List[str]:\n",
    "        \"\"\"Get test assertions from MBPP\"\"\"\n",
    "        return example['test_list']\n",
    "    \n",
    "    def iterate_samples(self):\n",
    "        \"\"\"Iterate through dataset samples\"\"\"\n",
    "        for i in range(self.num_samples):\n",
    "            yield self.dataset[i]\n",
    "\n",
    "\n",
    "# ==================== Code Analysis ====================\n",
    "class CodeAnalyzer:\n",
    "    @staticmethod\n",
    "    def extract_function_signature(code: str) -> str:\n",
    "        \"\"\"Extract function signature from code\"\"\"\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.FunctionDef):\n",
    "                    args = [arg.arg for arg in node.args.args]\n",
    "                    return f\"{node.name}({', '.join(args)})\"\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Fallback: regex extraction\n",
    "        match = re.search(r'def\\s+(\\w+)\\s*\\((.*?)\\)', code)\n",
    "        if match:\n",
    "            return f\"{match.group(1)}({match.group(2)})\"\n",
    "        return \"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_valid_python(code: str) -> bool:\n",
    "        \"\"\"Check if code is syntactically valid Python\"\"\"\n",
    "        try:\n",
    "            ast.parse(code)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_imports(code: str) -> set:\n",
    "        \"\"\"Extract imported modules\"\"\"\n",
    "        imports = set()\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.Import):\n",
    "                    for alias in node.names:\n",
    "                        imports.add(alias.name)\n",
    "                elif isinstance(node, ast.ImportFrom):\n",
    "                    imports.add(node.module)\n",
    "        except:\n",
    "            pass\n",
    "        return imports\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_functions(code: str) -> int:\n",
    "        \"\"\"Count number of functions defined\"\"\"\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            return sum(1 for node in ast.walk(tree) if isinstance(node, ast.FunctionDef))\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "\n",
    "# ==================== Hallucination Detection ====================\n",
    "class HallucinationDetector:\n",
    "    def __init__(self):\n",
    "        self.analyzer = CodeAnalyzer()\n",
    "    \n",
    "    # def detect_hallucination(self, prompt: str, generated_code: str, \n",
    "    #                         reference_code: str, test_cases: List[str]) -> Dict:\n",
    "    #     \"\"\"\n",
    "    #     Detect if generated code has hallucinations\n",
    "    #     Returns binary classification and detailed features\n",
    "    #     \"\"\"\n",
    "    #     features = {}\n",
    "        \n",
    "    #     # Feature 1: Syntax validity\n",
    "    #     features['generated_valid_syntax'] = self.analyzer.is_valid_python(generated_code)\n",
    "    #     features['reference_valid_syntax'] = self.analyzer.is_valid_python(reference_code)\n",
    "        \n",
    "    #     # Feature 2: Function signature match\n",
    "    #     gen_sig = self.analyzer.extract_function_signature(generated_code)\n",
    "    #     ref_sig = self.analyzer.extract_function_signature(reference_code)\n",
    "    #     features['signature_match'] = (gen_sig == ref_sig) if gen_sig and ref_sig else False\n",
    "    #     features['generated_signature'] = gen_sig\n",
    "    #     features['reference_signature'] = ref_sig\n",
    "        \n",
    "    #     # Feature 3: Import comparison\n",
    "    #     gen_imports = self.analyzer.extract_imports(generated_code)\n",
    "    #     ref_imports = self.analyzer.extract_imports(reference_code)\n",
    "    #     features['imports_overlap'] = len(gen_imports & ref_imports) / max(len(gen_imports | ref_imports), 1)\n",
    "        \n",
    "    #     # Feature 4: Code length ratio\n",
    "    #     gen_length = len(generated_code.strip())\n",
    "    #     ref_length = len(reference_code.strip())\n",
    "    #     features['length_ratio'] = gen_length / max(ref_length, 1)\n",
    "        \n",
    "    #     # Feature 5: Test execution (simplified - checks if test structure matches)\n",
    "    #     features['num_test_cases'] = len(test_cases)\n",
    "        \n",
    "    #     # Feature 6: Functional test execution\n",
    "    #     features['tests_passed'] = self._execute_tests(generated_code, test_cases)\n",
    "        \n",
    "    #     # Binary Classification: Has Hallucination?\n",
    "    #     # Hallucination if:\n",
    "    #     # - Invalid syntax OR\n",
    "    #     # - Signature doesn't match OR\n",
    "    #     # - Failed tests OR\n",
    "    #     # - Extremely short/long code (length ratio < 0.2 or > 5.0)\n",
    "    #     has_hallucination = (\n",
    "    #         not features['generated_valid_syntax'] or\n",
    "    #         not features['signature_match'] or\n",
    "    #         features['tests_passed'] == 0 or\n",
    "    #         features['length_ratio'] < 0.2 or\n",
    "    #         features['length_ratio'] > 5.0\n",
    "    #     )\n",
    "        \n",
    "    #     features['has_hallucination'] = has_hallucination\n",
    "    #     features['hallucination_binary'] = 1 if has_hallucination else 0\n",
    "        \n",
    "    #     return features\n",
    "    def detect_hallucination(self, prompt: str, generated_code: str, \n",
    "                            reference_code: str, test_cases: List[str]) -> Dict:\n",
    "        \n",
    "        # Complete the function if it's cut off\n",
    "        complete_generated = self._complete_function(prompt, generated_code)\n",
    "        features = {}\n",
    "        # Use complete function for analysis\n",
    "        features['generated_valid_syntax'] = self.analyzer.is_valid_python(complete_generated)\n",
    "        features['reference_valid_syntax'] = self.analyzer.is_valid_python(reference_code)\n",
    "        \n",
    "        # Extract signatures from complete code\n",
    "        gen_sig = self.analyzer.extract_function_signature(complete_generated)\n",
    "        ref_sig = self.analyzer.extract_function_signature(reference_code)\n",
    "        features['signature_match'] = (gen_sig == ref_sig) if gen_sig and ref_sig else False\n",
    "        \n",
    "        # Test the complete function\n",
    "        features['tests_passed'] = self._execute_tests(complete_generated, test_cases)\n",
    "        \n",
    "        # Calculate length ratio\n",
    "        gen_length = len(complete_generated.strip())\n",
    "        ref_length = len(reference_code.strip())\n",
    "        features['length_ratio'] = gen_length / max(ref_length, 1)\n",
    "\n",
    "        \n",
    "        # Feature 5: Test execution (simplified - checks if test structure matches)\n",
    "        features['num_test_cases'] = len(test_cases)\n",
    "        \n",
    "        # Feature 6: Functional test execution\n",
    "        features['tests_passed'] = self._execute_tests(generated_code, test_cases)\n",
    "        \n",
    "        # Binary Classification: Has Hallucination?\n",
    "        # Hallucination if:\n",
    "        # - Invalid syntax OR\n",
    "        # - Signature doesn't match OR\n",
    "        # - Failed tests OR\n",
    "        # - Extremely short/long code (length ratio < 0.2 or > 5.0)\n",
    "        has_hallucination = (\n",
    "            not features['generated_valid_syntax'] or\n",
    "            not features['signature_match'] or\n",
    "            features['tests_passed'] == 0 or\n",
    "            features['length_ratio'] < 0.2 or\n",
    "            features['length_ratio'] > 5.0\n",
    "        )\n",
    "        \n",
    "        features['has_hallucination'] = has_hallucination\n",
    "        features['hallucination_binary'] = 1 if has_hallucination else 0\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _complete_function(self, prompt: str, generated_code: str) -> str:\n",
    "        \"\"\"Ensure generated code forms a complete function\"\"\"\n",
    "        full_code = prompt + generated_code\n",
    "        \n",
    "        # Check if we have a complete function (has colon and indented body)\n",
    "        if '):' in generated_code and '\\n    ' in generated_code:\n",
    "            # Try to extract just the function\n",
    "            lines = full_code.split('\\n')\n",
    "            function_lines = []\n",
    "            in_function = False\n",
    "            indent_level = None\n",
    "            \n",
    "            for line in lines:\n",
    "                if line.strip().startswith('def '):\n",
    "                    in_function = True\n",
    "                    indent_level = len(line) - len(line.lstrip())\n",
    "                    function_lines.append(line)\n",
    "                elif in_function:\n",
    "                    current_indent = len(line) - len(line.lstrip())\n",
    "                    if line.strip() == '':\n",
    "                        function_lines.append(line)\n",
    "                    elif current_indent > indent_level:\n",
    "                        function_lines.append(line)\n",
    "                    else:\n",
    "                        break\n",
    "            \n",
    "            return '\\n'.join(function_lines)\n",
    "        \n",
    "        return full_code\n",
    "    \n",
    "    def _execute_tests(self, code: str, test_cases: List[str]) -> int:\n",
    "        \"\"\"\n",
    "        Execute test cases on generated code\n",
    "        Returns number of passed tests\n",
    "        \"\"\"\n",
    "        if not self.analyzer.is_valid_python(code):\n",
    "            return 0\n",
    "        \n",
    "        passed = 0\n",
    "        namespace = {}\n",
    "        \n",
    "        try:\n",
    "            # Execute the generated code\n",
    "            exec(code, namespace)\n",
    "            \n",
    "            # Run each test case\n",
    "            for test in test_cases:\n",
    "                try:\n",
    "                    exec(test, namespace)\n",
    "                    passed += 1\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return passed\n",
    "\n",
    "# ===================Get Prompt =======================\n",
    "def get_prompt(self, example: Dict) -> str:\n",
    "    task_description = example.get('prompt', example.get('text', ''))\n",
    "    \n",
    "    func_name = 'solution'\n",
    "    if 'def ' in example['code']:\n",
    "        try:\n",
    "            func_name = example['code'].split('def ')[1].split('(')[0].strip()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    prompt = f\"\"\"# Task: {task_description}\n",
    "# Write a complete Python function to solve this task.\n",
    "# Requirements:\n",
    "# 1. Write ONLY the function code, no additional comments or test cases\n",
    "# 2. Make sure the function is syntactically correct\n",
    "# 3. Use appropriate parameter names\n",
    "# 4. Return the result, don't print it\n",
    "# Example 1: Write a function to calculate area of rectangle\n",
    "# def area_rectangle(length, width):\n",
    "#     return length * width\n",
    "\n",
    "# Example 2: Write a function to find factorial of a number  \n",
    "# def factorial(n):\n",
    "#     if n == 0:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return n * factorial(n-1)\n",
    "\n",
    "# Now write the requested function:\n",
    "def {func_name}(\"\"\"\n",
    "    return prompt\n",
    "# ==================== Evaluation Pipeline ====================\n",
    "class HallucinationEvaluator:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.model = CodeLlamaInference(config.MODEL_NAME, config.DEVICE)\n",
    "        self.dataset = MBPPDataset(config.NUM_SAMPLES)\n",
    "        self.detector = HallucinationDetector()\n",
    "        self.results = []\n",
    "    \n",
    "    def run_evaluation(self):\n",
    "        \"\"\"Run full evaluation pipeline\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Starting Hallucination Detection Evaluation\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        for idx, example in enumerate(tqdm(self.dataset.iterate_samples(), \n",
    "                                           total=self.config.NUM_SAMPLES,\n",
    "                                           desc=\"Evaluating\")):\n",
    "            # Get prompt and reference\n",
    "            prompt = self.dataset.get_prompt(example)\n",
    "            reference_code = self.dataset.get_reference_code(example)\n",
    "            test_cases = self.dataset.get_test_cases(example)\n",
    "            \n",
    "            # Generate code with LLM\n",
    "            generated_code = self.model.generate_code(\n",
    "                prompt,\n",
    "                max_new_tokens=self.config.MAX_NEW_TOKENS,\n",
    "                temperature=self.config.TEMPERATURE,\n",
    "                top_p=self.config.TOP_P\n",
    "            )\n",
    "            \n",
    "            # Detect hallucination\n",
    "            detection_result = self.detector.detect_hallucination(\n",
    "                prompt, generated_code, reference_code, test_cases\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                'example_id': idx,\n",
    "                'task_description': example.get('prompt', example.get('text', '')),\n",
    "                'prompt': prompt,\n",
    "                'generated_code': generated_code,\n",
    "                'reference_code': reference_code,\n",
    "                'test_cases': test_cases,\n",
    "                **detection_result\n",
    "            }\n",
    "            self.results.append(result)\n",
    "        \n",
    "        self._print_summary()\n",
    "        return self.results\n",
    "    \n",
    "    def _print_summary(self):\n",
    "        \"\"\"Print evaluation summary statistics\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Evaluation Summary\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        total = len(self.results)\n",
    "        hallucinated = sum(1 for r in self.results if r['has_hallucination'])\n",
    "        \n",
    "        print(f\"Total Samples: {total}\")\n",
    "        print(f\"Hallucinated: {hallucinated} ({hallucinated/total*100:.2f}%)\")\n",
    "        print(f\"Non-Hallucinated: {total - hallucinated} ({(total-hallucinated)/total*100:.2f}%)\")\n",
    "        print()\n",
    "        \n",
    "        # Breakdown by feature\n",
    "        syntax_errors = sum(1 for r in self.results if not r['generated_valid_syntax'])\n",
    "        sig_mismatches = sum(1 for r in self.results if not r['signature_match'])\n",
    "        test_failures = sum(1 for r in self.results if r['tests_passed'] == 0)\n",
    "        \n",
    "        print(f\"Syntax Errors: {syntax_errors} ({syntax_errors/total*100:.2f}%)\")\n",
    "        print(f\"Signature Mismatches: {sig_mismatches} ({sig_mismatches/total*100:.2f}%)\")\n",
    "        print(f\"Test Failures: {test_failures} ({test_failures/total*100:.2f}%)\")\n",
    "        print()\n",
    "        \n",
    "        avg_tests_passed = np.mean([r['tests_passed'] for r in self.results])\n",
    "        avg_length_ratio = np.mean([r['length_ratio'] for r in self.results])\n",
    "        \n",
    "        print(f\"Average Tests Passed: {avg_tests_passed:.2f}\")\n",
    "        print(f\"Average Length Ratio: {avg_length_ratio:.2f}\")\n",
    "    \n",
    "    def save_results(self, output_path: str = \"hallucination_results.json\"):\n",
    "        \"\"\"Save results to JSON file\"\"\"\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(self.results, f, indent=2)\n",
    "        print(f\"\\nResults saved to {output_path}\")\n",
    "    \n",
    "    def get_classification_data(self) -> Tuple[List[str], List[int]]:\n",
    "        \"\"\"\n",
    "        Get data for binary classification\n",
    "        Returns: (codes, labels) where labels are 0 (no hallucination) or 1 (hallucination)\n",
    "        \"\"\"\n",
    "        codes = [r['generated_code'] for r in self.results]\n",
    "        labels = [r['hallucination_binary'] for r in self.results]\n",
    "        return codes, labels\n",
    "\n",
    "\n",
    "# ==================== Main Execution ====================\n",
    "def main():\n",
    "    # Initialize configuration\n",
    "    config = Config()\n",
    "    \n",
    "    print(f\"Device: {config.DEVICE}\")\n",
    "    print(f\"Model: {config.MODEL_NAME}\")\n",
    "    print(f\"Samples: {config.NUM_SAMPLES}\")\n",
    "    \n",
    "    # Run evaluation\n",
    "    evaluator = HallucinationEvaluator(config)\n",
    "    results = evaluator.run_evaluation()\n",
    "    \n",
    "    # Save results\n",
    "    evaluator.save_results(\"hallucination_results.json\")\n",
    "    \n",
    "    # Get binary classification data\n",
    "    codes, labels = evaluator.get_classification_data()\n",
    "    print(f\"\\nBinary Classification Data:\")\n",
    "    print(f\"Total samples: {len(codes)}\")\n",
    "    print(f\"Positive (Hallucination): {sum(labels)}\")\n",
    "    print(f\"Negative (No Hallucination): {len(labels) - sum(labels)}\")\n",
    "    \n",
    "    # Example: Show first few results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Sample Results (First 3)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for i in range(min(3, len(results))):\n",
    "        result = results[i]\n",
    "        print(f\"Example {i+1}:\")\n",
    "        print(f\"Task: {result['task_description'][:80]}...\")\n",
    "        print(f\"Hallucination: {result['has_hallucination']}\")\n",
    "        print(f\"Valid Syntax: {result['generated_valid_syntax']}\")\n",
    "        print(f\"Signature Match: {result['signature_match']}\")\n",
    "        print(f\"Tests Passed: {result['tests_passed']}/{result['num_test_cases']}\")\n",
    "        print(f\"Length Ratio: {result['length_ratio']:.2f}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/beegfs/home/arofenitra.rarivonjy/ai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model: codellama/CodeLlama-7b-hf\n",
      "Samples: 5\n",
      "Loading model: codellama/CodeLlama-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda\n",
      "Creating simulated MBPP dataset...\n",
      "Created 3 samples, using 3\n",
      "\n",
      "============================================================\n",
      "Starting Hallucination Detection Evaluation\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  60%|███████████████████▊             | 3/5 [00:39<00:26, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluation Summary\n",
      "============================================================\n",
      "\n",
      "Total Samples: 3\n",
      "Hallucinated: 1 (33.33%)\n",
      "Non-Hallucinated: 2 (66.67%)\n",
      "\n",
      "Syntax Errors: 0 (0.00%)\n",
      "Signature Mismatches: 0 (0.00%)\n",
      "Test Failures: 1 (33.33%)\n",
      "\n",
      "Average Tests Passed: 1.67\n",
      "Average Length Ratio: 1.79\n",
      "\n",
      "Results saved to hallucination_results.json\n",
      "\n",
      "Binary Classification Data:\n",
      "Total samples: 3\n",
      "Positive (Hallucination): 1\n",
      "Negative (No Hallucination): 2\n",
      "\n",
      "============================================================\n",
      "Sample Results (First 3)\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "Task: Write a function to find the n largest integers from a given list of numbers, re...\n",
      "Hallucination: True\n",
      "Valid Syntax: True\n",
      "Signature Match: True\n",
      "Tests Passed: 0/3\n",
      "Length Ratio: 2.89\n",
      "------------------------------------------------------------\n",
      "Example 2:\n",
      "Task: Write a function to check if a string is a palindrome....\n",
      "Hallucination: False\n",
      "Valid Syntax: True\n",
      "Signature Match: True\n",
      "Tests Passed: 2/3\n",
      "Length Ratio: 1.39\n",
      "------------------------------------------------------------\n",
      "Example 3:\n",
      "Task: Write a function to calculate the factorial of a number....\n",
      "Hallucination: False\n",
      "Valid Syntax: True\n",
      "Signature Match: True\n",
      "Tests Passed: 3/3\n",
      "Length Ratio: 1.11\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MBPP Hallucination Detection for Code LLMs\n",
    "Compares CodeLlama-7B generated code against MBPP reference solutions\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "from typing import Dict, List, Any, Tuple\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "import ast\n",
    "import sys\n",
    "import io\n",
    "import contextlib\n",
    "\n",
    "# ==================== Configuration ====================\n",
    "class Config:\n",
    "    MODEL_NAME = \"codellama/CodeLlama-7b-hf\"\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    MAX_NEW_TOKENS = 512\n",
    "    TEMPERATURE = 0.2\n",
    "    TOP_P = 0.95\n",
    "    BATCH_SIZE = 1\n",
    "    NUM_SAMPLES = 5\n",
    "\n",
    "# ==================== Model Setup ====================\n",
    "class CodeLlamaInference:\n",
    "    def __init__(self, model_name: str, device: str):\n",
    "        print(f\"Loading model: {model_name}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\",\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        self.device = device\n",
    "        print(f\"Model loaded on {device}\")\n",
    "    \n",
    "    def generate_code(self, prompt: str, max_new_tokens: int = 512, \n",
    "                      temperature: float = 0.2, top_p: float = 0.95) -> str:\n",
    "        \"\"\"Generate code completion for given prompt with better stopping\"\"\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                eos_token_id=self.tokenizer.eos_token_id,\n",
    "                repetition_penalty=1.1,\n",
    "            )\n",
    "        \n",
    "        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        generated_code = generated_text[len(prompt):].strip()\n",
    "        \n",
    "        # Enhanced function completion\n",
    "        generated_code = self._complete_function(generated_code, prompt)\n",
    "        \n",
    "        return generated_code\n",
    "    \n",
    "    def _complete_function(self, generated_code: str, prompt: str) -> str:\n",
    "        \"\"\"Ensure the generated code forms a complete function\"\"\"\n",
    "        lines = generated_code.split('\\n')\n",
    "        completed_lines = []\n",
    "        in_function = False\n",
    "        expected_indent = None\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            stripped = line.strip()\n",
    "            \n",
    "            # Look for function definition\n",
    "            if stripped.startswith('def '):\n",
    "                in_function = True\n",
    "                completed_lines.append(line)\n",
    "                continue\n",
    "            \n",
    "            if in_function:\n",
    "                if not stripped:  # Empty line\n",
    "                    completed_lines.append(line)\n",
    "                    continue\n",
    "                    \n",
    "                # Check if this line is part of function body (has proper indentation)\n",
    "                current_indent = len(line) - len(line.lstrip())\n",
    "                if expected_indent is None and current_indent > 0:\n",
    "                    expected_indent = current_indent\n",
    "                \n",
    "                if expected_indent is not None and current_indent >= expected_indent:\n",
    "                    completed_lines.append(line)\n",
    "                else:\n",
    "                    # We've reached the end of the function\n",
    "                    break\n",
    "            else:\n",
    "                completed_lines.append(line)\n",
    "        \n",
    "        result = '\\n'.join(completed_lines)\n",
    "        \n",
    "        # If we don't have a complete function, try to add a basic return\n",
    "        if in_function and 'return' not in result:\n",
    "            # Add a simple return statement with proper indentation\n",
    "            if expected_indent is None:\n",
    "                expected_indent = 4\n",
    "            return_stmt = ' ' * expected_indent + 'return None'\n",
    "            result += '\\n' + return_stmt\n",
    "        \n",
    "        return result\n",
    "\n",
    "# ==================== MBPP Dataset Loader ====================\n",
    "class MBPPDataset:\n",
    "    def __init__(self, num_samples: int = 5):\n",
    "        \"\"\"\n",
    "        Simulated MBPP dataset since we can't load the real one\n",
    "        \"\"\"\n",
    "        print(\"Creating simulated MBPP dataset...\")\n",
    "        self.dataset = self._create_sample_data()\n",
    "        self.num_samples = min(num_samples, len(self.dataset))\n",
    "        print(f\"Created {len(self.dataset)} samples, using {self.num_samples}\")\n",
    "    \n",
    "    def _create_sample_data(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Create sample MBPP-like data for testing\"\"\"\n",
    "        samples = [\n",
    "            {\n",
    "                'prompt': 'Write a function to find the n largest integers from a given list of numbers, returned in descending order.',\n",
    "                'code': \"\"\"import heapq as hq\n",
    "def heap_queue_largest(nums, n):\n",
    "    largest_nums = hq.nlargest(n, nums)\n",
    "    return largest_nums\"\"\",\n",
    "                'test_list': [\n",
    "                    'assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58], 3) == [85, 75, 65]',\n",
    "                    'assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58], 2) == [85, 75]',\n",
    "                    'assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58], 5) == [85, 75, 65, 58, 35]'\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'prompt': 'Write a function to check if a string is a palindrome.',\n",
    "                'code': \"\"\"def is_palindrome(s):\n",
    "    s = s.lower().replace(\" \", \"\")\n",
    "    return s == s[::-1]\"\"\",\n",
    "                'test_list': [\n",
    "                    'assert is_palindrome(\"A man a plan a canal Panama\") == True',\n",
    "                    'assert is_palindrome(\"racecar\") == True', \n",
    "                    'assert is_palindrome(\"hello\") == False'\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                'prompt': 'Write a function to calculate the factorial of a number.',\n",
    "                'code': \"\"\"def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)\"\"\",\n",
    "                'test_list': [\n",
    "                    'assert factorial(5) == 120',\n",
    "                    'assert factorial(0) == 1',\n",
    "                    'assert factorial(1) == 1'\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        return samples\n",
    "    \n",
    "    def get_prompt(self, example: Dict) -> str:\n",
    "        \"\"\"Format MBPP example into a prompt for code generation\"\"\"\n",
    "        task_description = example.get('prompt', '')\n",
    "        \n",
    "        # Extract function name from reference code\n",
    "        func_name = 'solution'\n",
    "        if 'def ' in example['code']:\n",
    "            try:\n",
    "                func_name = example['code'].split('def ')[1].split('(')[0].strip()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Enhanced prompt with better instructions\n",
    "        prompt = f\"\"\"# Task: {task_description}\n",
    "# Write a complete Python function to solve this task.\n",
    "# Requirements:\n",
    "# 1. Write ONLY the function code\n",
    "# 2. Make sure the function is complete and syntactically correct\n",
    "# 3. Include proper parameter names based on the task\n",
    "# 4. Return the result, don't print it\n",
    "# 5. Ensure the function has proper indentation\n",
    "\n",
    "def {func_name}(\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def get_reference_code(self, example: Dict) -> str:\n",
    "        \"\"\"Get the reference solution from MBPP\"\"\"\n",
    "        return example['code']\n",
    "    \n",
    "    def get_test_cases(self, example: Dict) -> List[str]:\n",
    "        \"\"\"Get test assertions from MBPP\"\"\"\n",
    "        return example['test_list']\n",
    "    \n",
    "    def iterate_samples(self):\n",
    "        \"\"\"Iterate through dataset samples\"\"\"\n",
    "        for i in range(self.num_samples):\n",
    "            yield self.dataset[i]\n",
    "\n",
    "# ==================== Code Analysis ====================\n",
    "class CodeAnalyzer:\n",
    "    @staticmethod\n",
    "    def extract_function_signature(code: str) -> str:\n",
    "        \"\"\"Extract function signature from code\"\"\"\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.FunctionDef):\n",
    "                    args = [arg.arg for arg in node.args.args]\n",
    "                    return f\"{node.name}({', '.join(args)})\"\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Fallback: regex extraction\n",
    "        match = re.search(r'def\\s+(\\w+)\\s*\\((.*?)\\):', code)\n",
    "        if match:\n",
    "            return f\"{match.group(1)}({match.group(2)})\"\n",
    "        return \"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_valid_python(code: str) -> bool:\n",
    "        \"\"\"Check if code is syntactically valid Python\"\"\"\n",
    "        try:\n",
    "            ast.parse(code)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_imports(code: str) -> set:\n",
    "        \"\"\"Extract imported modules\"\"\"\n",
    "        imports = set()\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.Import):\n",
    "                    for alias in node.names:\n",
    "                        imports.add(alias.name)\n",
    "                elif isinstance(node, ast.ImportFrom):\n",
    "                    if node.module:\n",
    "                        imports.add(node.module)\n",
    "        except:\n",
    "            pass\n",
    "        return imports\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_function_body(code: str) -> str:\n",
    "        \"\"\"Extract just the function body for analysis\"\"\"\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.FunctionDef):\n",
    "                    # Return the function source\n",
    "                    return ast.get_source_segment(code, node)\n",
    "        except:\n",
    "            pass\n",
    "        return code\n",
    "\n",
    "# ==================== Hallucination Detection ====================\n",
    "class HallucinationDetector:\n",
    "    def __init__(self):\n",
    "        self.analyzer = CodeAnalyzer()\n",
    "    \n",
    "    def detect_hallucination(self, prompt: str, generated_code: str, \n",
    "                            reference_code: str, test_cases: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Detect if generated code has hallucinations\n",
    "        \"\"\"\n",
    "        # First, ensure we have a complete function\n",
    "        complete_generated = self._ensure_complete_function(prompt, generated_code)\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Feature 1: Syntax validity\n",
    "        features['generated_valid_syntax'] = self.analyzer.is_valid_python(complete_generated)\n",
    "        features['reference_valid_syntax'] = self.analyzer.is_valid_python(reference_code)\n",
    "        \n",
    "        # Feature 2: Function signature match\n",
    "        gen_sig = self.analyzer.extract_function_signature(complete_generated)\n",
    "        ref_sig = self.analyzer.extract_function_signature(reference_code)\n",
    "        features['signature_match'] = self._compare_signatures(gen_sig, ref_sig)\n",
    "        features['generated_signature'] = gen_sig\n",
    "        features['reference_signature'] = ref_sig\n",
    "        \n",
    "        # Feature 3: Import comparison\n",
    "        gen_imports = self.analyzer.extract_imports(complete_generated)\n",
    "        ref_imports = self.analyzer.extract_imports(reference_code)\n",
    "        union_imports = gen_imports | ref_imports\n",
    "        features['imports_overlap'] = len(gen_imports & ref_imports) / max(len(union_imports), 1) if union_imports else 0.0\n",
    "        \n",
    "        # Feature 4: Code length ratio\n",
    "        gen_length = len(complete_generated.strip())\n",
    "        ref_length = len(reference_code.strip())\n",
    "        features['length_ratio'] = gen_length / max(ref_length, 1)\n",
    "        \n",
    "        # Feature 5: Test execution\n",
    "        features['num_test_cases'] = len(test_cases)\n",
    "        features['tests_passed'] = self._execute_tests(complete_generated, test_cases)\n",
    "        \n",
    "        # Binary Classification: Has Hallucination?\n",
    "        has_hallucination = (\n",
    "            not features['generated_valid_syntax'] or\n",
    "            not features['signature_match'] or\n",
    "            features['tests_passed'] == 0 or\n",
    "            features['length_ratio'] < 0.2 or\n",
    "            features['length_ratio'] > 5.0\n",
    "        )\n",
    "        \n",
    "        features['has_hallucination'] = has_hallucination\n",
    "        features['hallucination_binary'] = 1 if has_hallucination else 0\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _ensure_complete_function(self, prompt: str, generated_code: str) -> str:\n",
    "        \"\"\"Ensure the generated code forms a complete, callable function\"\"\"\n",
    "        full_code = prompt + generated_code\n",
    "        \n",
    "        # Try to extract a complete function\n",
    "        try:\n",
    "            tree = ast.parse(full_code)\n",
    "            functions = [node for node in tree.body if isinstance(node, ast.FunctionDef)]\n",
    "            if functions:\n",
    "                # We found at least one function, return the source\n",
    "                func = functions[0]\n",
    "                return ast.get_source_segment(full_code, func)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Fallback: try to complete the function manually\n",
    "        lines = full_code.split('\\n')\n",
    "        function_lines = []\n",
    "        in_function = False\n",
    "        base_indent = None\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.strip().startswith('def '):\n",
    "                if in_function:\n",
    "                    break  # We already have a function, don't start another\n",
    "                in_function = True\n",
    "                function_lines.append(line)\n",
    "                # Set base indent\n",
    "                base_indent = len(line) - len(line.lstrip())\n",
    "            elif in_function:\n",
    "                current_indent = len(line) - len(line.lstrip())\n",
    "                if line.strip() == '':\n",
    "                    function_lines.append(line)\n",
    "                elif current_indent > base_indent:\n",
    "                    function_lines.append(line)\n",
    "                else:\n",
    "                    break  # End of function\n",
    "        \n",
    "        result = '\\n'.join(function_lines)\n",
    "        \n",
    "        # If we don't have a return statement, add one\n",
    "        if in_function and 'return' not in result:\n",
    "            if base_indent is not None:\n",
    "                return_line = ' ' * (base_indent + 4) + 'return None'\n",
    "                result += '\\n' + return_line\n",
    "        \n",
    "        return result if in_function else full_code\n",
    "    \n",
    "    def _compare_signatures(self, gen_sig: str, ref_sig: str) -> bool:\n",
    "        \"\"\"Compare function signatures with some flexibility\"\"\"\n",
    "        if not gen_sig or not ref_sig:\n",
    "            return False\n",
    "        \n",
    "        # Extract function names and parameters\n",
    "        gen_match = re.match(r'(\\w+)\\((.*)\\)', gen_sig)\n",
    "        ref_match = re.match(r'(\\w+)\\((.*)\\)', ref_sig)\n",
    "        \n",
    "        if not gen_match or not ref_match:\n",
    "            return False\n",
    "        \n",
    "        gen_name, gen_params = gen_match.groups()\n",
    "        ref_name, ref_params = ref_match.groups()\n",
    "        \n",
    "        # Compare number of parameters (more flexible)\n",
    "        gen_param_count = len([p for p in gen_params.split(',') if p.strip()])\n",
    "        ref_param_count = len([p for p in ref_params.split(',') if p.strip()])\n",
    "        \n",
    "        return gen_param_count == ref_param_count\n",
    "    \n",
    "    def _execute_tests(self, code: str, test_cases: List[str]) -> int:\n",
    "        \"\"\"Execute test cases on generated code safely\"\"\"\n",
    "        if not self.analyzer.is_valid_python(code):\n",
    "            return 0\n",
    "        \n",
    "        passed = 0\n",
    "        namespace = {}\n",
    "        \n",
    "        try:\n",
    "            # Execute the generated code in a safe environment\n",
    "            exec(code, namespace)\n",
    "            \n",
    "            for test in test_cases:\n",
    "                try:\n",
    "                    # Create a copy of namespace for each test\n",
    "                    test_namespace = namespace.copy()\n",
    "                    \n",
    "                    # Redirect stdout to avoid print statements\n",
    "                    with contextlib.redirect_stdout(io.StringIO()):\n",
    "                        with contextlib.redirect_stderr(io.StringIO()):\n",
    "                            exec(test, test_namespace)\n",
    "                    passed += 1\n",
    "                except Exception as e:\n",
    "                    # Test failed\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            # Code execution failed\n",
    "            return 0\n",
    "        \n",
    "        return passed\n",
    "\n",
    "# ==================== Evaluation Pipeline ====================\n",
    "class HallucinationEvaluator:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.model = CodeLlamaInference(config.MODEL_NAME, config.DEVICE)\n",
    "        self.dataset = MBPPDataset(config.NUM_SAMPLES)\n",
    "        self.detector = HallucinationDetector()\n",
    "        self.results = []\n",
    "    \n",
    "    def run_evaluation(self):\n",
    "        \"\"\"Run full evaluation pipeline\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Starting Hallucination Detection Evaluation\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        for idx, example in enumerate(tqdm(self.dataset.iterate_samples(), \n",
    "                                           total=self.config.NUM_SAMPLES,\n",
    "                                           desc=\"Evaluating\")):\n",
    "            try:\n",
    "                # Get prompt and reference\n",
    "                prompt = self.dataset.get_prompt(example)\n",
    "                reference_code = self.dataset.get_reference_code(example)\n",
    "                test_cases = self.dataset.get_test_cases(example)\n",
    "                \n",
    "                # Generate code with LLM\n",
    "                generated_code = self.model.generate_code(\n",
    "                    prompt,\n",
    "                    max_new_tokens=self.config.MAX_NEW_TOKENS,\n",
    "                    temperature=self.config.TEMPERATURE,\n",
    "                    top_p=self.config.TOP_P\n",
    "                )\n",
    "                \n",
    "                # Detect hallucination\n",
    "                detection_result = self.detector.detect_hallucination(\n",
    "                    prompt, generated_code, reference_code, test_cases\n",
    "                )\n",
    "                \n",
    "                # Store results\n",
    "                result = {\n",
    "                    'example_id': idx,\n",
    "                    'task_description': example.get('prompt', ''),\n",
    "                    'prompt': prompt,\n",
    "                    'generated_code': generated_code,\n",
    "                    'reference_code': reference_code,\n",
    "                    'test_cases': test_cases,\n",
    "                    **detection_result\n",
    "                }\n",
    "                self.results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing example {idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        self._print_summary()\n",
    "        return self.results\n",
    "    \n",
    "    def _print_summary(self):\n",
    "        \"\"\"Print evaluation summary statistics\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Evaluation Summary\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        if not self.results:\n",
    "            print(\"No results to summarize\")\n",
    "            return\n",
    "            \n",
    "        total = len(self.results)\n",
    "        hallucinated = sum(1 for r in self.results if r['has_hallucination'])\n",
    "        \n",
    "        print(f\"Total Samples: {total}\")\n",
    "        print(f\"Hallucinated: {hallucinated} ({hallucinated/total*100:.2f}%)\")\n",
    "        print(f\"Non-Hallucinated: {total - hallucinated} ({(total-hallucinated)/total*100:.2f}%)\")\n",
    "        print()\n",
    "        \n",
    "        # Breakdown by feature\n",
    "        syntax_errors = sum(1 for r in self.results if not r['generated_valid_syntax'])\n",
    "        sig_mismatches = sum(1 for r in self.results if not r['signature_match'])\n",
    "        test_failures = sum(1 for r in self.results if r['tests_passed'] == 0)\n",
    "        \n",
    "        print(f\"Syntax Errors: {syntax_errors} ({syntax_errors/total*100:.2f}%)\")\n",
    "        print(f\"Signature Mismatches: {sig_mismatches} ({sig_mismatches/total*100:.2f}%)\")\n",
    "        print(f\"Test Failures: {test_failures} ({test_failures/total*100:.2f}%)\")\n",
    "        print()\n",
    "        \n",
    "        avg_tests_passed = np.mean([r['tests_passed'] for r in self.results])\n",
    "        avg_length_ratio = np.mean([r['length_ratio'] for r in self.results])\n",
    "        \n",
    "        print(f\"Average Tests Passed: {avg_tests_passed:.2f}\")\n",
    "        print(f\"Average Length Ratio: {avg_length_ratio:.2f}\")\n",
    "    \n",
    "    def save_results(self, output_path: str = \"hallucination_results.json\"):\n",
    "        \"\"\"Save results to JSON file\"\"\"\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(self.results, f, indent=2)\n",
    "        print(f\"\\nResults saved to {output_path}\")\n",
    "    \n",
    "    def get_classification_data(self) -> Tuple[List[str], List[int]]:\n",
    "        \"\"\"\n",
    "        Get data for binary classification\n",
    "        Returns: (codes, labels) where labels are 0 (no hallucination) or 1 (hallucination)\n",
    "        \"\"\"\n",
    "        codes = [r['generated_code'] for r in self.results]\n",
    "        labels = [r['hallucination_binary'] for r in self.results]\n",
    "        return codes, labels\n",
    "\n",
    "# ==================== Main Execution ====================\n",
    "def main():\n",
    "    # Initialize configuration\n",
    "    config = Config()\n",
    "    \n",
    "    print(f\"Device: {config.DEVICE}\")\n",
    "    print(f\"Model: {config.MODEL_NAME}\")\n",
    "    print(f\"Samples: {config.NUM_SAMPLES}\")\n",
    "    \n",
    "    # Run evaluation\n",
    "    evaluator = HallucinationEvaluator(config)\n",
    "    results = evaluator.run_evaluation()\n",
    "    \n",
    "    # Save results\n",
    "    evaluator.save_results(\"hallucination_results.json\")\n",
    "    \n",
    "    if results:\n",
    "        # Get binary classification data\n",
    "        codes, labels = evaluator.get_classification_data()\n",
    "        print(f\"\\nBinary Classification Data:\")\n",
    "        print(f\"Total samples: {len(codes)}\")\n",
    "        print(f\"Positive (Hallucination): {sum(labels)}\")\n",
    "        print(f\"Negative (No Hallucination): {len(labels) - sum(labels)}\")\n",
    "        \n",
    "        # Example: Show first few results\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Sample Results (First 3)\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        for i in range(min(3, len(results))):\n",
    "            result = results[i]\n",
    "            print(f\"Example {i+1}:\")\n",
    "            print(f\"Task: {result['task_description'][:80]}...\")\n",
    "            print(f\"Hallucination: {result['has_hallucination']}\")\n",
    "            print(f\"Valid Syntax: {result['generated_valid_syntax']}\")\n",
    "            print(f\"Signature Match: {result['signature_match']}\")\n",
    "            print(f\"Tests Passed: {result['tests_passed']}/{result['num_test_cases']}\")\n",
    "            print(f\"Length Ratio: {result['length_ratio']:.2f}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T09:13:26.370654Z",
     "iopub.status.busy": "2025-11-17T09:13:26.369508Z",
     "iopub.status.idle": "2025-11-17T09:13:39.524150Z",
     "shell.execute_reply": "2025-11-17T09:13:39.523513Z",
     "shell.execute_reply.started": "2025-11-17T09:13:26.370593Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model: codellama/CodeLlama-7b-hf\n",
      "Samples: 5\n",
      "Loading model: codellama/CodeLlama-7b-hf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda\n",
      "Loading MBPP dataset...\n",
      "Loaded 427 total samples, using 5\n"
     ]
    }
   ],
   "source": [
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "print(f\"Model: {config.MODEL_NAME}\")\n",
    "print(f\"Samples: {config.NUM_SAMPLES}\")\n",
    "\n",
    "# Run evaluation\n",
    "evaluator = HallucinationEvaluator(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T07:43:22.731168Z",
     "iopub.status.busy": "2025-11-17T07:43:22.730321Z",
     "iopub.status.idle": "2025-11-17T08:34:29.081647Z",
     "shell.execute_reply": "2025-11-17T08:34:29.080991Z",
     "shell.execute_reply.started": "2025-11-17T07:43:22.731146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Hallucination Detection Evaluation\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████| 5/5 [01:30<00:00, 18.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluation Summary\n",
      "============================================================\n",
      "\n",
      "Total Samples: 5\n",
      "Hallucinated: 5 (100.00%)\n",
      "Non-Hallucinated: 0 (0.00%)\n",
      "\n",
      "Syntax Errors: 0 (0.00%)\n",
      "Signature Mismatches: 5 (100.00%)\n",
      "Test Failures: 5 (100.00%)\n",
      "\n",
      "Average Tests Passed: 0.00\n",
      "Average Length Ratio: 1.24\n",
      "\n",
      "Results saved to hallucination_results.json\n",
      "\n",
      "Binary Classification Data:\n",
      "Total samples: 5\n",
      "Positive (Hallucination): 5\n",
      "Negative (No Hallucination): 0\n",
      "\n",
      "============================================================\n",
      "Sample Results (First 3)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluator.run_evaluation()\n",
    "\n",
    "# Save results\n",
    "evaluator.save_results(\"hallucination_results.json\")\n",
    "\n",
    "# Get binary classification data\n",
    "codes, labels = evaluator.get_classification_data()\n",
    "print(f\"\\nBinary Classification Data:\")\n",
    "print(f\"Total samples: {len(codes)}\")\n",
    "print(f\"Positive (Hallucination): {sum(labels)}\")\n",
    "print(f\"Negative (No Hallucination): {len(labels) - sum(labels)}\")\n",
    "\n",
    "# Example: Show first few results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Sample Results (First 3)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T08:34:29.082467Z",
     "iopub.status.busy": "2025-11-17T08:34:29.082283Z",
     "iopub.status.idle": "2025-11-17T08:34:29.087839Z",
     "shell.execute_reply": "2025-11-17T08:34:29.087129Z",
     "shell.execute_reply.started": "2025-11-17T08:34:29.082450Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Task: \n",
      "    Write a function to find the shared elements from the given two lists.\n",
      "Hallucination: True\n",
      "Valid Syntax: True\n",
      "Signature Match: False\n",
      "Tests Passed: 0/3\n",
      "Length Ratio: 1.62\n",
      "------------------------------------------------------------\n",
      "Example 2:\n",
      "Task: \n",
      "    Write a python function to identify non-prime numbers.\n",
      "Hallucination: True\n",
      "Valid Syntax: True\n",
      "Signature Match: False\n",
      "Tests Passed: 0/4\n",
      "Length Ratio: 0.96\n",
      "------------------------------------------------------------\n",
      "Example 3:\n",
      "Task: \n",
      "    Write a function to find the n largest integers from a given list of numbers, returned in descending order.\n",
      "Hallucination: True\n",
      "Valid Syntax: True\n",
      "Signature Match: False\n",
      "Tests Passed: 0/3\n",
      "Length Ratio: 1.06\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(min(3, len(results))):\n",
    "    result = results[i]\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"\"\"Task: \n",
    "    {result['task_description']}\"\"\")\n",
    "    print(f\"Hallucination: {result['has_hallucination']}\")\n",
    "    print(f\"Valid Syntax: {result['generated_valid_syntax']}\")\n",
    "    print(f\"Signature Match: {result['signature_match']}\")\n",
    "    print(f\"Tests Passed: {result['tests_passed']}/{result['num_test_cases']}\")\n",
    "    print(f\"Length Ratio: {result['length_ratio']:.2f}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T08:57:06.120924Z",
     "iopub.status.busy": "2025-11-17T08:57:06.120331Z",
     "iopub.status.idle": "2025-11-17T08:57:06.126023Z",
     "shell.execute_reply": "2025-11-17T08:57:06.125281Z",
     "shell.execute_reply.started": "2025-11-17T08:57:06.120903Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a function to find the n largest integers from a given list of numbers, returned in descending order.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['task_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T08:57:22.464166Z",
     "iopub.status.busy": "2025-11-17T08:57:22.463559Z",
     "iopub.status.idle": "2025-11-17T08:57:22.468974Z",
     "shell.execute_reply": "2025-11-17T08:57:22.468274Z",
     "shell.execute_reply.started": "2025-11-17T08:57:22.464141Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['has_hallucination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T08:57:38.251511Z",
     "iopub.status.busy": "2025-11-17T08:57:38.250829Z",
     "iopub.status.idle": "2025-11-17T08:57:38.256663Z",
     "shell.execute_reply": "2025-11-17T08:57:38.255970Z",
     "shell.execute_reply.started": "2025-11-17T08:57:38.251486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_id': 2,\n",
       " 'task_description': 'Write a function to find the n largest integers from a given list of numbers, returned in descending order.',\n",
       " 'prompt': '# Task: Write a function to find the n largest integers from a given list of numbers, returned in descending order.\\n# Write a Python function to solve this task\\ndef heap_queue_largest(',\n",
       " 'generated_code': 'arr):\\n    import heapq\\n    return [heapq.nlargest(n, arr)[-1] for n in range(len(arr), 0, -1)]',\n",
       " 'reference_code': 'import heapq as hq\\ndef heap_queue_largest(nums,n):\\n  largest_nums = hq.nlargest(n, nums)\\n  return largest_nums',\n",
       " 'test_cases': ['assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],3)==[85, 75, 65]',\n",
       "  'assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],2)==[85, 75]',\n",
       "  'assert heap_queue_largest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[85, 75, 65, 58, 35]'],\n",
       " 'generated_valid_syntax': True,\n",
       " 'reference_valid_syntax': True,\n",
       " 'signature_match': False,\n",
       " 'tests_passed': 0,\n",
       " 'length_ratio': 1.0636363636363637,\n",
       " 'num_test_cases': 3,\n",
       " 'has_hallucination': True,\n",
       " 'hallucination_binary': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T09:13:39.525650Z",
     "iopub.status.busy": "2025-11-17T09:13:39.525397Z",
     "iopub.status.idle": "2025-11-17T10:44:31.526828Z",
     "shell.execute_reply": "2025-11-17T10:44:31.525905Z",
     "shell.execute_reply.started": "2025-11-17T09:13:39.525624Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Hallucination Detection Evaluation\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [1:30:51<00:00, 545.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluation Summary\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'has_hallucination'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/2394091635.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Save results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hallucination_results2.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48/746795745.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48/746795745.py\u001b[0m in \u001b[0;36m_print_summary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mhallucinated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_hallucination'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total Samples: {total}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_48/746795745.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0mhallucinated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_hallucination'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total Samples: {total}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'has_hallucination'"
     ]
    }
   ],
   "source": [
    "results = evaluator.run_evaluation()\n",
    "\n",
    "# Save results\n",
    "evaluator.save_results(\"hallucination_results2.json\")\n",
    "\n",
    "# Get binary classification data\n",
    "codes, labels = evaluator.get_classification_data()\n",
    "print(f\"\\nBinary Classification Data:\")\n",
    "print(f\"Total samples: {len(codes)}\")\n",
    "print(f\"Positive (Hallucination): {sum(labels)}\")\n",
    "print(f\"Negative (No Hallucination): {len(labels) - sum(labels)}\")\n",
    "\n",
    "# Example: Show first few results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Sample Results (First 3)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T10:44:31.527351Z",
     "iopub.status.idle": "2025-11-17T10:44:31.527579Z",
     "shell.execute_reply": "2025-11-17T10:44:31.527471Z",
     "shell.execute_reply.started": "2025-11-17T10:44:31.527462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(min(3, len(results))):\n",
    "    result = results[i]\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Task: {result['task_description']}...\")\n",
    "    print(f\"Hallucination: {result['has_hallucination']}\")\n",
    "    print(f\"Valid Syntax: {result['generated_valid_syntax']}\")\n",
    "    print(f\"Signature Match: {result['signature_match']}\")\n",
    "    print(f\"Tests Passed: {result['tests_passed']}/{result['num_test_cases']}\")\n",
    "    print(f\"Length Ratio: {result['length_ratio']:.2f}\")\n",
    "    print(\"-\" * 60)\n",
    "for i in range(min(3, len(results))):\n",
    "    result = results[i]\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Task: {result['task_description']}...\")\n",
    "    print(f\"Hallucination: {result['has_hallucination']}\")\n",
    "    print(f\"Valid Syntax: {result['generated_valid_syntax']}\")\n",
    "    print(f\"Signature Match: {result['signature_match']}\")\n",
    "    print(f\"Tests Passed: {result['tests_passed']}/{result['num_test_cases']}\")\n",
    "    print(f\"Length Ratio: {result['length_ratio']:.2f}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New implementation of classifier, cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AdvancedCodeAnalyzer:\n",
    "    def extract_features(self, prompt: str, generated_code: str, reference_code: str = None) -> Dict:\n",
    "        features = {}\n",
    "        \n",
    "        # Syntax and Structure Features\n",
    "        features['valid_syntax'] = self.is_valid_python(generated_code)\n",
    "        features['code_length'] = len(generated_code)\n",
    "        features['line_count'] = generated_code.count('\\n') + 1\n",
    "        features['avg_line_length'] = len(generated_code) / max(features['line_count'], 1)\n",
    "        \n",
    "        # Code Complexity Features\n",
    "        features['has_imports'] = len(self.extract_imports(generated_code)) > 0\n",
    "        features['function_count'] = self.count_functions(generated_code)\n",
    "        features['has_loops'] = self.has_loops(generated_code)\n",
    "        features['has_conditionals'] = self.has_conditionals(generated_code)\n",
    "        features['has_exceptions'] = self.has_exceptions(generated_code)\n",
    "        \n",
    "        # Code Pattern Features\n",
    "        features['has_print'] = 'print(' in generated_code\n",
    "        features['has_comments'] = '#' in generated_code\n",
    "        features['has_docstring'] = '\"\"\"' in generated_code or \"'''\" in generated_code\n",
    "        features['has_todo'] = 'TODO' in generated_code.upper()\n",
    "        \n",
    "        # Token-based Features\n",
    "        tokens = self.tokenize_code(generated_code)\n",
    "        features['token_count'] = len(tokens)\n",
    "        features['unique_token_ratio'] = len(set(tokens)) / max(len(tokens), 1)\n",
    "        features['keyword_density'] = self.keyword_density(tokens)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def has_loops(self, code: str) -> bool:\n",
    "        return any(keyword in code for keyword in [' for ', ' while ', ' range('])\n",
    "    \n",
    "    def has_conditionals(self, code: str) -> bool:\n",
    "        return any(keyword in code for keyword in [' if ', ' elif ', ' else:'])\n",
    "    \n",
    "    def has_exceptions(self, code: str) -> bool:\n",
    "        return any(keyword in code for keyword in [' try:', ' except', ' raise ', ' finally:'])\n",
    "    \n",
    "    def tokenize_code(self, code: str) -> List[str]:\n",
    "        # Simple tokenization for feature extraction\n",
    "        tokens = re.findall(r'\\b\\w+\\b|[^\\w\\s]', code)\n",
    "        return [token for token in tokens if token.strip()]\n",
    "    \n",
    "    def keyword_density(self, tokens: List[str]) -> float:\n",
    "        python_keywords = {'def', 'return', 'if', 'else', 'for', 'while', 'import', 'from', \n",
    "                          'class', 'try', 'except', 'with', 'as', 'in', 'is', 'and', 'or', 'not'}\n",
    "        keyword_count = sum(1 for token in tokens if token in python_keywords)\n",
    "        return keyword_count / max(len(tokens), 1)\n",
    "class AlignmentAnalyzer:\n",
    "    def extract_alignment_features(self, prompt: str, generated_code: str) -> Dict:\n",
    "        features = {}\n",
    "        \n",
    "        # Keyword overlap between prompt and code\n",
    "        prompt_keywords = set(re.findall(r'\\b\\w+\\b', prompt.lower()))\n",
    "        code_keywords = set(re.findall(r'\\b\\w+\\b', generated_code.lower()))\n",
    "        \n",
    "        features['keyword_overlap'] = len(prompt_keywords & code_keywords) / max(len(prompt_keywords), 1)\n",
    "        features['prompt_coverage'] = len(prompt_keywords & code_keywords) / max(len(code_keywords), 1)\n",
    "        \n",
    "        # Task-specific feature detection\n",
    "        features['mentions_test'] = 'test' in prompt.lower()\n",
    "        features['mentions_function'] = 'function' in prompt.lower()\n",
    "        features['mentions_return'] = 'return' in prompt.lower()\n",
    "        \n",
    "        # Parameter alignment\n",
    "        features['parameter_match'] = self.check_parameter_alignment(prompt, generated_code)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def check_parameter_alignment(self, prompt: str, code: str) -> bool:\n",
    "        # Extract expected parameters from prompt\n",
    "        expected_params = set()\n",
    "        if 'parameter' in prompt.lower():\n",
    "            # Simple heuristic - look for parameter mentions\n",
    "            param_matches = re.findall(r'parameter\\s+(\\w+)', prompt.lower())\n",
    "            expected_params.update(param_matches)\n",
    "        \n",
    "        # Extract actual parameters from code\n",
    "        try:\n",
    "            tree = ast.parse(code)\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, ast.FunctionDef):\n",
    "                    actual_params = {arg.arg for arg in node.args.args}\n",
    "                    return bool(expected_params & actual_params) if expected_params else True\n",
    "        except:\n",
    "            pass\n",
    "        return False\n",
    "class SemanticAnalyzer:\n",
    "    def __init__(self):\n",
    "        # You can use sentence transformers or other embedding models\n",
    "        self.similarity_threshold = 0.7\n",
    "    \n",
    "    def extract_semantic_features(self, generated_code: str, reference_code: str) -> Dict:\n",
    "        features = {}\n",
    "        \n",
    "        # Code structure similarity\n",
    "        features['structure_similarity'] = self.structure_similarity(generated_code, reference_code)\n",
    "        \n",
    "        # Function name similarity\n",
    "        features['func_name_similarity'] = self.function_name_similarity(generated_code, reference_code)\n",
    "        \n",
    "        # Import similarity\n",
    "        features['import_similarity'] = self.import_similarity(generated_code, reference_code)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def structure_similarity(self, code1: str, code2: str) -> float:\n",
    "        # Compare AST structures\n",
    "        try:\n",
    "            tree1 = ast.parse(code1)\n",
    "            tree2 = ast.parse(code2)\n",
    "            \n",
    "            # Count different node types\n",
    "            nodes1 = Counter(type(node).__name__ for node in ast.walk(tree1))\n",
    "            nodes2 = Counter(type(node).__name__ for node in ast.walk(tree2))\n",
    "            \n",
    "            # Calculate Jaccard similarity\n",
    "            all_nodes = set(nodes1.keys()) | set(nodes2.keys())\n",
    "            intersection = sum(min(nodes1.get(node, 0), nodes2.get(node, 0)) for node in all_nodes)\n",
    "            union = sum(max(nodes1.get(node, 0), nodes2.get(node, 0)) for node in all_nodes)\n",
    "            \n",
    "            return intersection / union if union > 0 else 0\n",
    "        except:\n",
    "            return 0\n",
    "def create_positive_dataset(mbpp_dataset, num_samples: int = 1000):\n",
    "    \"\"\"Use MBPP reference solutions as positive examples\"\"\"\n",
    "    positive_examples = []\n",
    "    \n",
    "    for example in mbpp_dataset.iterate_samples():\n",
    "        if len(positive_examples) >= num_samples:\n",
    "            break\n",
    "            \n",
    "        positive_examples.append({\n",
    "            'prompt': example.get('prompt', ''),\n",
    "            'code': example['code'],\n",
    "            'label': 0,  # Non-hallucinated\n",
    "            'tests_passed': True,\n",
    "            'source': 'mbpp_reference'\n",
    "        })\n",
    "    \n",
    "    return positive_examples\n",
    "def create_negative_dataset(positive_examples, num_samples: int = 1000):\n",
    "    \"\"\"Create negative examples by perturbing positive examples\"\"\"\n",
    "    negative_examples = []\n",
    "    \n",
    "    perturbation_strategies = [\n",
    "        ('syntax_error', self.introduce_syntax_errors),\n",
    "        ('logical_error', self.introduce_logical_errors),\n",
    "        ('semantic_error', self.introduce_semantic_errors),\n",
    "        ('structural_error', self.introduce_structural_errors),\n",
    "        ('irrelevant_code', self.add_irrelevant_code)\n",
    "    ]\n",
    "    \n",
    "    for positive in positive_examples:\n",
    "        if len(negative_examples) >= num_samples:\n",
    "            break\n",
    "            \n",
    "        # Apply random perturbations\n",
    "        strategy_name, strategy_fn = random.choice(perturbation_strategies)\n",
    "        perturbed_code = strategy_fn(positive['code'])\n",
    "        \n",
    "        negative_examples.append({\n",
    "            'prompt': positive['prompt'],\n",
    "            'code': perturbed_code,\n",
    "            'label': 1,  # Hallucinated\n",
    "            'perturbation_type': strategy_name,\n",
    "            'source': 'perturbed'\n",
    "        })\n",
    "    \n",
    "    return negative_examples\n",
    "\n",
    "def introduce_syntax_errors(self, code: str) -> str:\n",
    "    \"\"\"Introduce syntax errors\"\"\"\n",
    "    errors = [\n",
    "        lambda c: c.replace(':', ''),  # Remove colon\n",
    "        lambda c: c.replace('def ', 'def'),  # Remove space after def\n",
    "        lambda c: c.replace('return ', 'return'),  # Remove space after return\n",
    "        lambda c: c + '\\n    undefined_function()',  # Call undefined function\n",
    "        lambda c: re.sub(r'(\\w+)\\(', r'\\1(', c),  # Remove space before parenthesis\n",
    "    ]\n",
    "    return random.choice(errors)(code)\n",
    "\n",
    "def introduce_logical_errors(self, code: str) -> str:\n",
    "    \"\"\"Introduce logical errors\"\"\"\n",
    "    errors = [\n",
    "        lambda c: c.replace('+', '-'),  # Change operator\n",
    "        lambda c: c.replace('*', '/'),  # Change operator\n",
    "        lambda c: c.replace('==', '!='),  # Change comparison\n",
    "        lambda c: c.replace('>', '<'),  # Change comparison\n",
    "        lambda c: re.sub(r'return (.*)', r'return \\1 + 1', c),  # Add offset\n",
    "    ]\n",
    "    return random.choice(errors)(code)\n",
    "\n",
    "def introduce_semantic_errors(self, code: str) -> str:\n",
    "    \"\"\"Introduce semantic errors\"\"\"\n",
    "    errors = [\n",
    "        lambda c: c.replace('sort', 'reverse'),  # Wrong method\n",
    "        lambda c: c.replace('append', 'extend'),  # Wrong method\n",
    "        lambda c: re.sub(r'def (\\w+)', r'def wrong_\\1', c),  # Wrong function name\n",
    "        lambda c: re.sub(r'(\\w+) =', r'wrong_\\1 =', c),  # Wrong variable name\n",
    "    ]\n",
    "    return random.choice(errors)(code)\n",
    "def create_model_generated_dataset(model, mbpp_dataset, num_samples: int = 500):\n",
    "    \"\"\"Generate examples using the model and label based on test results\"\"\"\n",
    "    generated_examples = []\n",
    "    \n",
    "    for example in mbpp_dataset.iterate_samples():\n",
    "        if len(generated_examples) >= num_samples:\n",
    "            break\n",
    "            \n",
    "        prompt = example.get('prompt', '')\n",
    "        generated_code = model.generate_code(prompt)\n",
    "        test_cases = example.get('test_list', [])\n",
    "        \n",
    "        # Determine label based on test execution\n",
    "        tests_passed = self.execute_tests(generated_code, test_cases)\n",
    "        label = 0 if tests_passed == len(test_cases) else 1\n",
    "        \n",
    "        generated_examples.append({\n",
    "            'prompt': prompt,\n",
    "            'code': generated_code,\n",
    "            'label': label,\n",
    "            'tests_passed': tests_passed,\n",
    "            'total_tests': len(test_cases),\n",
    "            'source': 'model_generated'\n",
    "        })\n",
    "    \n",
    "    return generated_examples\n",
    "class HallucinationFeatureEngineer:\n",
    "    def __init__(self):\n",
    "        self.code_analyzer = AdvancedCodeAnalyzer()\n",
    "        self.alignment_analyzer = AlignmentAnalyzer()\n",
    "        self.semantic_analyzer = SemanticAnalyzer()\n",
    "    \n",
    "    def extract_all_features(self, prompt: str, generated_code: str, reference_code: str = None) -> Dict:\n",
    "        \"\"\"Extract comprehensive features for classification\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Code quality features\n",
    "        features.update(self.code_analyzer.extract_features(prompt, generated_code))\n",
    "        \n",
    "        # Prompt-code alignment features\n",
    "        features.update(self.alignment_analyzer.extract_alignment_features(prompt, generated_code))\n",
    "        \n",
    "        # Semantic similarity features (if reference available)\n",
    "        if reference_code:\n",
    "            features.update(self.semantic_analyzer.extract_semantic_features(generated_code, reference_code))\n",
    "        \n",
    "        return features\n",
    "\n",
    "# Usage for training\n",
    "def prepare_training_data(positive_examples, negative_examples, model_generated_examples):\n",
    "    feature_engineer = HallucinationFeatureEngineer()\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    all_examples = positive_examples + negative_examples + model_generated_examples\n",
    "    \n",
    "    for example in all_examples:\n",
    "        features = feature_engineer.extract_all_features(\n",
    "            example['prompt'], \n",
    "            example['code'],\n",
    "            reference_code=None  # Don't use reference in production\n",
    "        )\n",
    "        X.append(list(features.values()))\n",
    "        y.append(example['label'])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def train_hallucination_classifier(X, y):\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train LightGBM\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Feature importance analysis\n",
    "def analyze_feature_importance(model, feature_names):\n",
    "    importance = model.feature_importances_\n",
    "    feature_imp = sorted(zip(feature_names, importance), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Feature Importance:\")\n",
    "    for feature, imp in feature_imp[:10]:  # Top 10 features\n",
    "        print(f\"{feature}: {imp:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
